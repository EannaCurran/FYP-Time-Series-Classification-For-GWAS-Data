{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sktime.transformations.panel.rocket import MiniRocket\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening up file containing GWAS data and reading in\n",
    "\n",
    "file = open(\"Second_GWAS/Second_GWAS_Add.raw\", \"r\")\n",
    "lines = file.readlines()\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GWAS data into DF in the correct format\n",
    "\n",
    "columns = lines[0].strip(\"\\n\").split(\" \")\n",
    "columns = [n.split(\"_\", 1)[0] for n in columns]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "data = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    newRow = line.strip(\"\\n\").split(\" \")\n",
    "    for position in range(0, len(newRow)):\n",
    "        if newRow[position] == \"0\":\n",
    "            newRow[position] = \"2\"\n",
    "        elif newRow[position] == \"2\":\n",
    "            newRow[position] = \"0\"\n",
    "        \n",
    "    data.append(newRow)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55\n",
       "0    54\n",
       "Name: PHENOTYPE, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see split between cases and controls\n",
    "\n",
    "df[\"PHENOTYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-encoding phenotype column\n",
    "\n",
    "#df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "#df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"1\",\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns and seperating phenotype column\n",
    "phenotype = df.pop(\"PHENOTYPE\")\n",
    "dfTest = df.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in df with most common allele for \n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idf = pd.DataFrame(imp.fit_transform(dfTest))\n",
    "idf.columns = dfTest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to be numberical\n",
    "\n",
    "dfTest = idf.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training data and testing data\n",
    "\n",
    "xTrain, xTtest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for RandomForst\n",
    "\n",
    "bootstrap = [True, False]\n",
    "maxDepth = list(range(10,110,10))\n",
    "maxFeatures = [\"auto\", \"sqrt\"]\n",
    "minSamplesLeaf = [1,2,3,4]\n",
    "minSamplesSplit = [2,3,5]\n",
    "nEstimators = list(range(100,1100,100))\n",
    "\n",
    "hyperparameters = dict(bootstrap=bootstrap, max_depth=maxDepth, max_features=maxFeatures, min_samples_leaf=minSamplesLeaf,\n",
    "                       min_samples_split=minSamplesSplit, n_estimators=nEstimators)\n",
    "\n",
    "rfd = RandomForestClassifier()\n",
    "\n",
    "clf = GridSearchCV(rfd, hyperparameters, cv=10)\n",
    "\n",
    "bestModel = clf.fit(dfTest, phenotype)\n",
    "print('Best bootstrap:', bestModel.best_estimator_.get_params()['bootstrap'])\n",
    "print('Best max_depth:', bestModel.best_estimator_.get_params()['max_depth'])\n",
    "print('Best max_features:', bestModel.best_estimator_.get_params()['max_features'])\n",
    "print('Best min_samples_leaf:', bestModel.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_samples_split:', bestModel.best_estimator_.get_params()['min_samples_split'])\n",
    "print('Best n_estimators:', bestModel.best_estimator_.get_params()['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score: 1.0\n",
      "Testing accuracy score: 0.5454545454545454\n",
      "[[10  3]\n",
      " [12  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.77      0.57        13\n",
      "           1       0.73      0.40      0.52        20\n",
      "\n",
      "    accuracy                           0.55        33\n",
      "   macro avg       0.59      0.58      0.54        33\n",
      "weighted avg       0.62      0.55      0.54        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(xTrain, yTrain)\n",
    "yPredicted = rfc.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = rfc.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))\n",
    "print(classification_report(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting df to array structure\n",
    "\n",
    "dfTestSeries = from_2d_array_to_nested(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting time series data into training data and testing data\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from training split\n",
    "\n",
    "yTrain = yTrain.values\n",
    "yTest = yTest.values\n",
    "\n",
    "xTrain = xTrain.reset_index()\n",
    "xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "xTest = xTest.reset_index()\n",
    "xTest = xTest.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting training data to MiniRocket\n",
    "\n",
    "minirocket = MiniRocket()\n",
    "minirocket.fit(xTrain)\n",
    "xTrainTransform = minirocket.transform(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the transformed data to the ridge classifier\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "classifier.fit(xTrainTransform, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating test predictions \n",
    "\n",
    "xTestTransform = minirocket.transform(xTest)\n",
    "yPredict = classifier.predict(xTestTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing results\n",
    "\n",
    "print(\"Accuracy with Rocket: %2.3f\" % accuracy_score(yTest, yPredict))\n",
    "print(confusion_matrix(yTest, yPredict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
