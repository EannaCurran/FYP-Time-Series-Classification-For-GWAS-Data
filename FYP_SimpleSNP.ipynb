{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7638ef4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17020/3560360242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapelet_based\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMrSEQLClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_arrow_head\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_basic_motions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatatypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_panel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_2d_array_to_nested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eanna\\sktime\\sktime\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m ]\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m from sktime.datasets._data_io import (\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mload_acsf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mload_airline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eanna\\sktime\\sktime\\datasets\\_data_io.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_from_tsfile_to_dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_constant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtsa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexponential_smoothing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mETSModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbk_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcf_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mforecasting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTLForecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mholtwinters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExponentialSmoothing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHolt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleExpSmoothing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC  \n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.datasets import load_arrow_head, load_basic_motions\n",
    "\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from sktime.datasets import load_arrow_head \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ae5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening up file containing GWAS data and reading in\n",
    "\n",
    "file = open(\"GWAS_Add.raw\", \"r\")\n",
    "lines = file.readlines()\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GWAS data into DF in the correct format\n",
    "\n",
    "columns = lines[0].strip(\"\\n\").split(\" \")\n",
    "columns = [n.split(\"_\", 1)[0] for n in columns]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "data = []\n",
    "for line in lines[1:]:\n",
    "    newRow = line.strip(\"\\n\").split(\" \")\n",
    "    for position in range(0, len(newRow)):\n",
    "        if newRow[position] == \"0\":\n",
    "            newRow[position] = \"2\"\n",
    "        elif newRow[position] == \"2\":\n",
    "            newRow[position] = \"0\"\n",
    "        \n",
    "    data.append(newRow)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to see if control SNPs have been encoded correctly control\n",
    "\n",
    "df1 = df[[\"rs2222162\",\"PHENOTYPE\"]]\n",
    "df1[df1[\"PHENOTYPE\"] == \"1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to see if cases SNPs have been encoded correctly case\n",
    "\n",
    "df1 = df[[\"rs2222162\",\"PHENOTYPE\"]]\n",
    "df1[df1[\"PHENOTYPE\"] == \"0\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only selecting 100 SNPs located on chromosome 2 \n",
    "\n",
    "dfAlleles = df.loc[:, \"rs11684739\":\"rs2521953\"]\n",
    "dfAllelesLarge = df.loc[:, \"rs11684739\":\"rs6757306\"]\n",
    "dfInfo = df.loc[:, :\"PHENOTYPE\"]\n",
    "df = dfInfo.join(dfAlleles)\n",
    "dfLarge = dfInfo.join(dfAllelesLarge)\n",
    "len(df.columns), len(dfLarge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Phenotype values\n",
    "\n",
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"1\",\"control\")\n",
    "\n",
    "dfLarge[\"PHENOTYPE\"] = dfLarge[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "dfLarge[\"PHENOTYPE\"] = dfLarge[\"PHENOTYPE\"].replace(\"1\",\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29252aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving copy of df\n",
    "\n",
    "dfSave = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-encoding SNP of interest to generate stronger signal\n",
    "\n",
    "#df.loc[df.PHENOTYPE == \"case\", [\"rs2222162\"]] = \"2\"\n",
    "#df.loc[df.PHENOTYPE == \"control\", [\"rs2222162\"]] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ID columns and \n",
    "\n",
    "phenotype = df.pop(\"PHENOTYPE\")\n",
    "dfTest = df.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "dfTestLarge = dfLarge.drop(columns=[\"PHENOTYPE\",\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing SNP entries and replacing with most frequent value for that SNP of other entries\n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idf = pd.DataFrame(imp.fit_transform(dfTest))\n",
    "idf.columns = dfTest.columns\n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idfLarge = pd.DataFrame(imp.fit_transform(dfTestLarge))\n",
    "idfLarge.columns = dfTestLarge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba170fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to be numberical\n",
    "\n",
    "idf = idf.apply(pd.to_numeric)\n",
    "idfLarge = idfLarge.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e992c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying over large df\n",
    "\n",
    "dfLargeSave = idfLarge.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting index of SNP of interest\n",
    "\n",
    "idfT = idf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 0 - control\n",
    "\n",
    "position = idfT[0].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[0][0:position+1], color=\"tab:blue\")\n",
    "plt.plot(idfT[0][position-1:position+1], color=\"red\")\n",
    "plt.plot(idfT[0][position:],color=\"tab:blue\")\n",
    "phenotype[0], idfT[0][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 8 - control\n",
    "\n",
    "position = idfT[8].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[8][0:position-1], color=\"tab:blue\")\n",
    "plt.plot(idfT[8][position-2:position+1], color=\"red\")\n",
    "plt.plot(idfT[8][position:],color=\"tab:blue\")\n",
    "phenotype[8], idfT[8][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 2 - case\n",
    "\n",
    "position = idfT[2].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[2][0:position], color=\"tab:blue\")\n",
    "plt.plot(idfT[2][position-1:position+1], color=\"red\")\n",
    "plt.plot(idfT[2][position:],color=\"tab:blue\")\n",
    "phenotype[2], idfT[2][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8259631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 88 - case\n",
    "\n",
    "position = idfT[88].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[88][0:position], color=\"tab:blue\")\n",
    "plt.plot(idfT[88][position-1:position+1], color=\"red\")\n",
    "plt.plot(idfT[88][position:],color=\"tab:blue\")\n",
    "phenotype[88], idfT[88][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac217c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training data and testing data\n",
    "\n",
    "xTrain, xTtest, yTrain, yTest = train_test_split(idf, phenotype, train_size=0.6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808066c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for RandomForst\n",
    "\n",
    "# bootstrap = [True, False]\n",
    "# maxDepth = list(range(10,110,10))\n",
    "# maxFeatures = [\"auto\", \"sqrt\"]\n",
    "# minSamplesLeaf = [1,2,3,4]\n",
    "# minSamplesSplit = [2,3,5]\n",
    "# nEstimators = list(range(100,1100,100))\n",
    "\n",
    "# hyperparameters = dict(bootstrap=bootstrap, max_depth=maxDepth, max_features=maxFeatures, min_samples_leaf=minSamplesLeaf,\n",
    "#                       min_samples_split=minSamplesSplit, n_estimators=nEstimators)\n",
    "\n",
    "# rfd = RandomForestClassifier()\n",
    "\n",
    "# clf = GridSearchCV(rfd, hyperparameters, cv=10)\n",
    "\n",
    "# bestModel = clf.fit(idf, phenotype)\n",
    "# print('Best bootstrap:', bestModel.best_estimator_.get_params()['bootstrap'])\n",
    "# print('Best max_depth:', bestModel.best_estimator_.get_params()['max_depth'])\n",
    "# print('Best max_features:', bestModel.best_estimator_.get_params()['max_features'])\n",
    "# print('Best min_samples_leaf:', bestModel.best_estimator_.get_params()['min_samples_leaf'])\n",
    "# print('Best min_samples_split:', bestModel.best_estimator_.get_params()['min_samples_split'])\n",
    "# print('Best n_estimators:', bestModel.best_estimator_.get_params()['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using decision tree and printing results\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True, max_depth=100, max_features=\"sqrt\", \n",
    "                             min_samples_leaf=4, min_samples_split=2, n_estimators=100)\n",
    "rfc.fit(xTrain, yTrain)\n",
    "yPredicted = rfc.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = rfc.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))\n",
    "print(classification_report(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting features that random forest classifier found important\n",
    "\n",
    "rf =  pd.DataFrame({\"featrue\": idf.columns, \"importance\":rfc.feature_importances_})\n",
    "sorted_idx = rfc.feature_importances_.argsort()\n",
    "plt.barh(idf.columns[sorted_idx[-10:]], rfc.feature_importances_[sorted_idx[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for KNN\n",
    "\n",
    "\n",
    "# leafSize = list(range(1,30))\n",
    "# neighbours = list(range(1,30))\n",
    "# p = [1,2]\n",
    "# hyperparameters = dict(leaf_size=leafSize, n_neighbors=neighbours, p=p)\n",
    "\n",
    "# knn = KNeighborsClassifier() \n",
    "\n",
    "# clf = GridSearchCV(knn, hyperparameters, cv=10)\n",
    "\n",
    "# bestModel = clf.fit(idf, phenotype)\n",
    "# print('Best leaf_size:', bestModel.best_estimator_.get_params()['leaf_size'])\n",
    "# print('Best p:', bestModel.best_estimator_.get_params()['p'])\n",
    "# print('Best n_neighbors:', bestModel.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using KNN and printing results\n",
    "\n",
    "knnClf = KNeighborsClassifier(leaf_size=1, n_neighbors=22,p=2 ) \n",
    "knnClf.fit(xTrain, yTrain)\n",
    "yPredicted = knnClf.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = knnClf.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for KNN\n",
    "\n",
    "# C = [0.1,1, 10, 100]\n",
    "# gamma = [1,0.1,0.01,0.001]\n",
    "# kernel = ['rbf', 'poly', 'sigmoid']\n",
    "# hyperparameters = dict(C=C,gamma=gamma,kernel=kernel)\n",
    "\n",
    "# SVM = SVC()\n",
    "\n",
    "# clf = GridSearchCV(SVM, hyperparameters, refit=True,cv=10)\n",
    "\n",
    "# bestModel = clf.fit(idf, phenotype)\n",
    "# print('Best C:', bestModel.best_estimator_.get_params()['C'])\n",
    "# print('Best gamma:', bestModel.best_estimator_.get_params()['gamma'])\n",
    "# print('Best kernel:', bestModel.best_estimator_.get_params()['kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b28f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using sigmoid SVC and printing results\n",
    "\n",
    "SVM = SVC(kernel=\"sigmoid\", C=100, gamma=0.001)\n",
    "SVM.fit(xTrain, yTrain)\n",
    "yPredicted = SVM.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = SVM.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e57aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using sigmoid SVC and printing results\n",
    "\n",
    "RCLF = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "RCLF.fit(xTrain, yTrain)\n",
    "yPredicted = RCLF.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = RCLF.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eea43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting df columns into 2d numpy array time series\n",
    "\n",
    "idf = idf.apply(pd.to_numeric)\n",
    "idfSeries = from_2d_array_to_nested(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02256e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting time seriesdata into training data and testing data\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38854bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from training split\n",
    "\n",
    "yTrain = yTrain.values\n",
    "yTest = yTest.values\n",
    "\n",
    "xTrain = xTrain.reset_index()\n",
    "xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "xTest = xTest.reset_index()\n",
    "xTest = xTest.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe15c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running rocket kernal transformation on training data\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(xTrain)\n",
    "xTrainTransform = rocket.transform(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS Data from rocket transformation using Ridge Classifier\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "classifier.fit(xTrainTransform, yTrain)\n",
    "xTestTransform = rocket.transform(xTest)\n",
    "yPredict = classifier.predict(xTestTransform)\n",
    "print(\"Accuracy with Rocket: %2.3f\" % metrics.accuracy_score(yTest, yPredict))\n",
    "print(confusion_matrix(yTest, yPredict))\n",
    "print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a03426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifying GWAS data using MrSEQL\n",
    "\n",
    "ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "ms.fit(xTrain, yTrain)\n",
    "yPredict = ms.predict(xTest)\n",
    "print(\"Accuracy with MrSEQL: %2.3f\" % metrics.accuracy_score(yTest, yPredict))\n",
    "print(confusion_matrix(yTest, yPredict))\n",
    "print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bec982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to setup df for testing\n",
    "\n",
    "def SetupTest(df):\n",
    "    \n",
    "    imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "    idf = pd.DataFrame(imp.fit_transform(df))\n",
    "    idf.columns = df.columns\n",
    "    idf = idf.apply(pd.to_numeric)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d81cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to generate graph that displays change in accuracy for a given classifier as the length of the target SNP\n",
    "#    is increased\n",
    "\n",
    "def GenerateSignalGraph(df, classifier):\n",
    "    \n",
    "    results = []\n",
    "    dfTest = df.copy(deep=True)\n",
    "    phenotype = dfTest.pop(\"PHENOTYPE\")\n",
    "    dfTest = dfTest.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "    for n in range(1,10):\n",
    "        classifierTemp = clone(classifier)\n",
    "        dfTest.insert(dfTest.columns.get_loc(\"rs2222162\"), f\"rs222216_{n}\", dfTest[\"rs2222162\"])\n",
    "        idf = SetupTest(dfTest)\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(idf, phenotype, train_size=0.6, random_state=1)\n",
    "        classifierTemp.fit(xTrain, yTrain)\n",
    "        yPredict = classifierTemp.predict(xTest)\n",
    "        results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "        \n",
    "        if n == 9:\n",
    "            print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "            print(confusion_matrix(yTest, yPredict))\n",
    "            print(classification_report(yTest, yPredict))\n",
    "            classifier = classifierTemp\n",
    "            \n",
    "    plt.plot(results)\n",
    "    return dfTest, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for Random Forst\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True, max_depth=100, max_features=\"sqrt\", \n",
    "                             min_samples_leaf=4, min_samples_split=2, n_estimators=100)\n",
    "idf, rfc = GenerateSignalGraph(dfSave, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting features that random forest classifier found important for singal length 10\n",
    "\n",
    "rf =  pd.DataFrame({\"featrue\": idf.columns, \"importance\":rfc.feature_importances_})\n",
    "sorted_idx = rfc.feature_importances_.argsort()\n",
    "plt.barh(idf.columns[sorted_idx[-10:]], rfc.feature_importances_[sorted_idx[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for Knn\n",
    "\n",
    "knnClf = KNeighborsClassifier(leaf_size=1, n_neighbors=22,p=2 ) \n",
    "_ =  GenerateSignalGraph(dfSave, knnClf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff39396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for SVM\n",
    "\n",
    "SVM = SVC(kernel=\"sigmoid\", C=100, gamma=0.001)\n",
    "_ = GenerateSignalGraph(dfSave, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for Ridge classifier\n",
    "\n",
    "RCLF = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "_ = GenerateSignalGraph(dfSave, RCLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e75a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for Rocket\n",
    "\n",
    "results = []\n",
    "dfTest = dfSave.copy(deep=True)\n",
    "phenotype = dfTest.pop(\"PHENOTYPE\")\n",
    "dfTest = dfTest.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "\n",
    "for n in range(1,10):\n",
    "    \n",
    "    dfTest.insert(dfTest.columns.get_loc(\"rs2222162\"), f\"rs222216_{n}\", dfTest[\"rs2222162\"])\n",
    "    idf = SetupTest(dfTest)\n",
    "    idfSeries = from_2d_array_to_nested(idf)\n",
    "    \n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    \n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "\n",
    "    xTrain = xTrain.reset_index()\n",
    "    xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "    xTest = xTest.reset_index()\n",
    "    xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "    rocket = Rocket()\n",
    "    rocket.fit(xTrain)\n",
    "    xTrainTransform = rocket.transform(xTrain)\n",
    "    \n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "    xTestTransform = rocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "    results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "    \n",
    "    if n == 9:\n",
    "        \n",
    "        print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "        print(confusion_matrix(yTest, yPredict))\n",
    "        print(classification_report(yTest, yPredict))\n",
    "    \n",
    "    \n",
    "_ = plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48911062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for MrSEQL\n",
    "\n",
    "results = []\n",
    "dfTest = dfSave.copy(deep=True)\n",
    "phenotype = dfTest.pop(\"PHENOTYPE\")\n",
    "dfTest = dfTest.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "idf=None\n",
    "\n",
    "for n in range(1,10):\n",
    "    \n",
    "    dfTest.insert(dfTest.columns.get_loc(\"rs2222162\"), f\"rs2222162_{n}\", dfTest[\"rs2222162\"])\n",
    "    idf = SetupTest(dfTest)\n",
    "    idfSeries = from_2d_array_to_nested(idf)\n",
    "    \n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    \n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "\n",
    "    xTrain = xTrain.reset_index()\n",
    "    xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "    xTest = xTest.reset_index()\n",
    "    xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "    ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "    ms.fit(xTrain, yTrain)\n",
    "    yPredict = ms.predict(xTest)\n",
    "    results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "    \n",
    "    if n == 9:\n",
    "        print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "        print(confusion_matrix(yTest, yPredict))\n",
    "        print(classification_report(yTest, yPredict))\n",
    "    \n",
    "_ = plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing SNPs with increased singal length\n",
    "\n",
    "idfT = idf.T\n",
    "position = idfT[8].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[8][0:position-1], color=\"tab:blue\")\n",
    "plt.plot(idfT[8][position-2:position+1], color=\"red\")\n",
    "plt.plot(idfT[8][position:],color=\"tab:blue\")\n",
    "phenotype[position], idfT[8][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1807bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to see if singal SNPs have the expected value\n",
    "\n",
    "idfT[8].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 10 Length signal to df with 600 SNPs\n",
    "\n",
    "for n in range(1,10):\n",
    "    \n",
    "    idfLarge.insert(idfLarge.columns.get_loc(\"rs2222162\"), f\"rs2222162_{n}\", idfLarge[\"rs2222162\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking first 100 SNPs of large df are expected\n",
    "\n",
    "idfLarge.iloc[:, 0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb70f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check to see if we add 1 SNP what happens to accuracy for MrSEQL with singal length 10\n",
    "\n",
    "dfTest = dfTest.join(dfLarge[\"rs13432248\"])\n",
    "#dfTest = dfTest.join(dfLarge[\"rs3109320\"])\n",
    "idf = SetupTest(dfTest)\n",
    "idfSeries = from_2d_array_to_nested(idf)\n",
    "    \n",
    "xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    \n",
    "yTrain = yTrain.values\n",
    "yTest = yTest.values\n",
    "\n",
    "xTrain = xTrain.reset_index()\n",
    "xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "xTest = xTest.reset_index()\n",
    "xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "ms.fit(xTrain, yTrain)\n",
    "yPredict = ms.predict(xTest)\n",
    "\n",
    "print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "print(confusion_matrix(yTest, yPredict))\n",
    "print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy for MrSEQL with singal length 10 when we add additional SNPs to dataset\n",
    "\n",
    "results = []\n",
    "for index in range(109,129):\n",
    "    \n",
    "    print(f\"current run {index-108}\")\n",
    "    currentDf = idfLarge.iloc[:, 0:index]\n",
    "    idf = currentDf.apply(pd.to_numeric)\n",
    "    idfSeries = from_2d_array_to_nested(idf)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "\n",
    "    xTrain = xTrain.reset_index()\n",
    "    xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "    xTest = xTest.reset_index()\n",
    "    xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "    ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "    ms.fit(xTrain, yTrain)\n",
    "    yPredict = ms.predict(xTest)\n",
    "    \n",
    "    results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "    \n",
    "_ = plt.plot(results)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
