{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.transformations.panel.rocket import MiniRocket\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening up file containing GWAS data and reading in\n",
    "\n",
    "file = open(\"Second_GWAS/Second_GWAS_Add.raw\", \"r\")\n",
    "lines = file.readlines()\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GWAS data into DF in the correct format\n",
    "\n",
    "columns = lines[0].strip(\"\\n\").split(\" \")\n",
    "columns = [n.split(\"_\", 1)[0] for n in columns]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "data = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    newRow = line.strip(\"\\n\").split(\" \")\n",
    "    for position in range(0, len(newRow)):\n",
    "        if newRow[position] == \"0\":\n",
    "            newRow[position] = \"2\"\n",
    "        elif newRow[position] == \"2\":\n",
    "            newRow[position] = \"0\"\n",
    "        \n",
    "    data.append(newRow)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55\n",
       "0    54\n",
       "Name: PHENOTYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see split between cases and controls\n",
    "\n",
    "df[\"PHENOTYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 41313)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing shape of df\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FID', 'IID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE', 'rs7433861',\n",
       "       'rs1166974', 'rs1166975', 'rs10446372',\n",
       "       ...\n",
       "       'rs4030335', 'rs7374010', 'rs9877345', 'rs7373662', 'rs12630742',\n",
       "       'rs11916265', 'rs7374354', 'rs9325418', 'rs9325420', 'rs10154902'],\n",
       "      dtype='object', length=41313)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing shape of df\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"1\",\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns and seperating phenotype column\n",
    "phenotype = df.pop(\"PHENOTYPE\")\n",
    "dfTest = df.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in df with most common allele for \n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idf = pd.DataFrame(imp.fit_transform(dfTest))\n",
    "idf.columns = dfTest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to be numberical\n",
    "\n",
    "dfTest = idf.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'case'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising first 100 SNPs of first case\n",
    "\n",
    "dfTranspose = dfTest.T\n",
    "plt.xticks([])\n",
    "plt.plot(dfTranspose[0][0:100], color=\"tab:blue\")\n",
    "phenotype[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training data and testing data\n",
    "\n",
    "xTrain, xTtest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for RandomForest on entire dataset: 0.5393939393939394\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using RandomForest\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTtest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredicted = rfc.predict(xTtest)\n",
    "    results.append(accuracy_score(yTest, yPredicted))\n",
    "    \n",
    "print(f\"Average accuracy for RandomForest on entire dataset: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting df to array structure\n",
    "\n",
    "dfTestSeries = from_2d_array_to_nested(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MiniRocket on entire dataset: 0.47272727272727266\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using MiniRocket\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.7)\n",
    "    minirocket = MiniRocket()\n",
    "    minirocket.fit(xTrain)\n",
    "    xTrainTransform = minirocket.transform(xTrain)\n",
    "\n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "\n",
    "    xTestTransform = minirocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MiniRocket on entire dataset: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNPS = ['rs9867035', 'rs7638693', 'rs9837776', 'rs2873392', 'rs6792542',\n",
    "       'rs1600058', 'rs1580295', 'rs1316579', 'rs834856', 'rs7430111',\n",
    "       'rs9817983', 'rs2085079', 'rs834858', 'rs834843', 'rs834864',\n",
    "       'rs9855684', 'rs1598120', 'rs6445172', 'rs9853565', 'rs1097157']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for RandomForest on selected SNPs: 0.7969696969696971\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using RandomForest\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTtest, yTrain, yTest = train_test_split(dfTest[SNPS], phenotype, train_size=0.7)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredicted = rfc.predict(xTtest)\n",
    "    results.append(accuracy_score(yTest, yPredicted))\n",
    "    \n",
    "print(f\"Average accuracy for RandomForest on selected SNPs: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestSeries = from_2d_array_to_nested(dfTest[SNPS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MiniRocket on selected SNPs: 0.793939393939394\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using MiniRocket\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.7)\n",
    "    minirocket = MiniRocket()\n",
    "    minirocket.fit(xTrain)\n",
    "    xTrainTransform = minirocket.transform(xTrain)\n",
    "\n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "\n",
    "    xTestTransform = minirocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MiniRocket on selected SNPs: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MrSEQL on selected SNP window: 0.787878787878788\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.7)\n",
    "    \n",
    "    ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "    ms.fit(xTrain, yTrain)\n",
    "    yPredict = ms.predict(xTest)\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MrSEQL on selected SNP window: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using MrSEQL\n",
    "\n",
    "#ms = MrSEQLClassifier(seql_mode=\"fs\")\n",
    "\n",
    "#ms.fit(xTrain, yTrain)\n",
    "#yPredict = ms.predict(xTest)\n",
    "\n",
    "#print(\"Accuracy with MrSEQL: %2.3f\" % metrics.accuracy_score(yTest, yPredict))\n",
    "#print(confusion_matrix(yTest, yPredict))\n",
    "#print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def GenerateWindowsTest(runs, classifierType, windowSize, threshold):\n",
    "\n",
    "    results = {}\n",
    "    numberOfWindows = len(dfTest.columns) // windowSize\n",
    "    \n",
    "    for k in range(1,runs+1):\n",
    "\n",
    "        print(f\"Run {k}\")\n",
    "\n",
    "        validationScores = []\n",
    "        testScores = []\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7)\n",
    "        xTrainSplit, xValidate, yTrainSplit, yValidate = train_test_split(xTrain, yTrain, train_size=0.7)\n",
    "\n",
    "        for n in range(0,numberOfWindows):\n",
    "\n",
    "            if(n%(numberOfWindows//10) == 0 and n != 0):\n",
    "                print(f\"Progress: {round((n/numberOfWindows) * 100)}%\")\n",
    "                \n",
    "            windowStart = n * windowSize\n",
    "            windowEnd = windowStart + windowSize\n",
    "            xTrainWindow = xTrainSplit.iloc[:,windowStart:windowEnd]\n",
    "            xValidateWindow = xValidate.iloc[:,windowStart:windowEnd]\n",
    "            \n",
    "            if classifierType == \"MiniRocket\":\n",
    "\n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xValidateWindowSeries = from_2d_array_to_nested(xValidateWindow)\n",
    "                minirocket = MiniRocket()\n",
    "                minirocket.fit(xTrainWindowSeries)\n",
    "                xTrainTransform = minirocket.transform(xTrainWindowSeries)\n",
    "                classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "                classifier.fit(xTrainTransform, yTrainSplit)\n",
    "                xValidateTransform = minirocket.transform(xValidateWindowSeries)\n",
    "                score = classifier.score(xValidateTransform, yValidate)\n",
    "            \n",
    "            elif  classifierType == \"MrSEQL\":\n",
    "                \n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xValidateWindowSeries = from_2d_array_to_nested(xValidateWindow)\n",
    "                ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "                ms.fit(xTrainWindowSeries, yTrainSplit)\n",
    "                yPredict = ms.predict(xValidateWindowSeries)\n",
    "                score = metrics.accuracy_score(yValidate, yPredict)\n",
    "            \n",
    "            elif classifierType == \"RandomForest\":\n",
    "                \n",
    "                rfc = RandomForestClassifier()\n",
    "                rfc.fit(xTrainWindow, yTrainSplit)\n",
    "                yPredict = rfc.predict(xValidateWindow)\n",
    "                score = metrics.accuracy_score(yValidate, yPredict)\n",
    "            \n",
    "            validationScores.append(score)\n",
    "\n",
    "        windowsAboveThreshold = [n for n in range(len(validationScores)) if validationScores[n] > threshold]\n",
    "        \n",
    "        print(f\"Window positions from validation with accuracy above threshold for run {k}\")\n",
    "        print(windowsAboveThreshold)\n",
    "\n",
    "        windowsAboveThresholdAfterTest = []\n",
    "\n",
    "        for n in windowsAboveThreshold:\n",
    "\n",
    "            windowStart = n * windowSize\n",
    "            windowEnd = windowStart + windowSize\n",
    "            xTrainWindow = xTrain.iloc[:,windowStart:windowEnd]\n",
    "            xTestWindow = xTest.iloc[:,windowStart:windowEnd]\n",
    "            \n",
    "            if classifierType == \"MiniRocket\":\n",
    "                \n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xTestWindowSeries = from_2d_array_to_nested(xTestWindow)\n",
    "                minirocket = MiniRocket()\n",
    "                minirocket.fit(xTrainWindowSeries)\n",
    "                xTrainTransform = minirocket.transform(xTrainWindowSeries)\n",
    "                classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "                classifier.fit(xTrainTransform, yTrain)\n",
    "                xTestTransform = minirocket.transform(xTestWindowSeries)\n",
    "                score = classifier.score(xTestTransform, yTest)\n",
    "                \n",
    "            elif  classifierType == \"MrSEQL\":\n",
    "                \n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xTestWindowSeries = from_2d_array_to_nested(xTestWindow)\n",
    "                ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "                ms.fit(xTrainWindowSeries, yTrain)\n",
    "                yPredict = ms.predict(xTestWindowSeries)\n",
    "                score = metrics.accuracy_score(yTest, yPredict)\n",
    "            \n",
    "            elif classifierType == \"RandomForest\":\n",
    "                \n",
    "                rfc = RandomForestClassifier()\n",
    "                rfc.fit(xTrainWindow, yTrain)\n",
    "                yPredict = rfc.predict(xTestWindow)\n",
    "                score = metrics.accuracy_score(yTest, yPredict)\n",
    "                \n",
    "            testScores.append(score)\n",
    "\n",
    "                \n",
    "        windowsAboveThresholdAfterTest = [windowsAboveThreshold[n] for n in range(len(windowsAboveThreshold)) if testScores[n] > threshold]\n",
    "        \n",
    "        print(f\"Window positions from validation with accuracy above threshold for run {k}\")\n",
    "        print(windowsAboveThresholdAfterTest)\n",
    "\n",
    "        for window in windowsAboveThresholdAfterTest:\n",
    "            if window in results:\n",
    "                results[window] += 1\n",
    "            else:\n",
    "                results[window] = 1\n",
    "                \n",
    "    sortedResults = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    updatedKeyResults = {}\n",
    "    for key, value in results.items():\n",
    "        newKeyStart = key*windowSize\n",
    "        newKeyEnd = newKeyStart + windowSize\n",
    "        updatedKeyResults[f\"{newKeyStart}-{newKeyEnd}\"] = value\n",
    "        \n",
    "    sortedResults = sorted(updatedKeyResults.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sortedResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[21, 33, 34, 56, 58, 62, 65, 74, 76, 80, 93, 98, 99, 102, 110, 116, 117, 127, 128, 131, 135, 139, 140, 142, 143, 144, 148, 149, 150, 157, 159, 166, 175, 177, 184, 186, 188, 189, 199, 200, 223, 225, 239, 243, 246, 247, 250, 251, 259, 274, 283, 291, 294, 303, 322, 337, 339, 345, 350, 352, 381, 385, 386, 387, 388, 390, 392, 398, 403, 424, 430, 435, 451, 457, 458, 465, 468, 470, 475, 487, 508, 509, 510, 514, 522, 523, 526, 528, 531, 532, 536, 540, 555, 560, 571, 572, 577, 578, 579, 588, 606, 607, 609, 620, 621, 630, 631, 635, 637, 640, 641, 650, 653, 654, 657, 673, 674, 686, 690, 701, 705, 724, 727, 734, 738, 740, 752, 755, 761, 766, 779, 792, 793, 802, 805, 818, 824]\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[33, 34, 116, 127, 128, 144, 157, 177, 350, 385, 430, 465, 514, 555, 620, 641, 653, 654, 724, 738, 752, 805]\n",
      "Run 2\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[14, 15, 26, 35, 53, 59, 76, 97, 98, 105, 106, 127, 128, 139, 140, 149, 164, 166, 173, 175, 177, 185, 202, 203, 204, 232, 243, 245, 247, 272, 273, 276, 280, 281, 283, 290, 299, 301, 304, 306, 319, 320, 321, 322, 328, 334, 335, 343, 345, 347, 361, 363, 369, 371, 373, 381, 382, 388, 398, 401, 406, 407, 412, 413, 419, 430, 434, 448, 465, 466, 467, 468, 481, 493, 513, 521, 539, 543, 545, 546, 548, 571, 587, 588, 590, 591, 593, 607, 610, 611, 612, 620, 641, 642, 643, 644, 654, 658, 693, 694, 724, 738, 741, 744, 759, 774, 780, 781, 784, 786, 794, 823]\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[128, 175, 177, 243, 283, 306, 401, 430, 593, 620, 641]\n",
      "Run 3\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[33, 34, 41, 58, 69, 128, 141, 142, 155, 158, 160, 161, 169, 200, 206, 207, 208, 221, 222, 252, 254, 264, 294, 298, 304, 306, 307, 325, 326, 334, 359, 360, 375, 381, 385, 392, 397, 398, 480, 492, 499, 516, 528, 533, 540, 555, 557, 572, 600, 629, 630, 632, 635, 641, 642, 643, 649, 651, 685, 733, 734, 736, 742, 777]\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[33, 34, 264, 385, 641]\n",
      "Run 4\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[5, 7, 9, 21, 30, 31, 33, 34, 36, 57, 58, 67, 74, 79, 88, 94, 105, 125, 128, 139, 141, 142, 148, 150, 157, 158, 173, 175, 180, 182, 186, 187, 188, 189, 195, 196, 198, 204, 206, 207, 208, 214, 223, 225, 232, 234, 236, 237, 240, 242, 243, 251, 256, 264, 272, 273, 283, 284, 287, 289, 294, 299, 300, 301, 312, 319, 321, 339, 343, 346, 347, 348, 351, 365, 374, 382, 383, 384, 391, 413, 415, 416, 418, 426, 433, 438, 465, 473, 479, 480, 481, 482, 485, 491, 493, 499, 500, 510, 513, 531, 532, 536, 542, 546, 549, 552, 555, 558, 559, 564, 583, 589, 595, 597, 603, 609, 610, 611, 614, 628, 642, 645, 649, 650, 654, 657, 658, 668, 673, 687, 689, 698, 706, 724, 725, 727, 746, 780, 781, 792, 798, 802, 824, 825]\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[33, 34, 58, 142, 175, 237, 242, 264, 536, 546, 642, 673, 725, 780]\n",
      "Run 5\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[1, 3, 5, 6, 7, 8, 9, 16, 17, 20, 21, 22, 23, 30, 32, 33, 34, 35, 36, 37, 39, 43, 51, 56, 57, 58, 67, 70, 71, 77, 78, 89, 94, 98, 105, 106, 124, 127, 128, 130, 140, 141, 142, 148, 149, 157, 159, 160, 162, 165, 166, 173, 174, 175, 177, 186, 187, 194, 195, 196, 197, 201, 204, 205, 206, 207, 208, 211, 212, 219, 221, 223, 225, 229, 232, 233, 234, 243, 244, 246, 252, 256, 260, 262, 264, 271, 273, 277, 279, 281, 286, 290, 293, 296, 297, 298, 299, 301, 302, 304, 306, 308, 319, 322, 328, 339, 340, 343, 344, 352, 357, 370, 372, 376, 382, 383, 396, 398, 401, 407, 409, 424, 425, 426, 431, 439, 440, 445, 446, 454, 467, 468, 474, 478, 491, 496, 500, 503, 509, 510, 512, 521, 535, 536, 537, 539, 544, 547, 550, 556, 557, 575, 577, 578, 580, 582, 584, 587, 589, 598, 599, 600, 604, 610, 611, 612, 613, 621, 623, 624, 630, 641, 642, 645, 647, 650, 654, 657, 658, 659, 660, 661, 666, 675, 679, 681, 684, 685, 686, 687, 690, 706, 710, 715, 717, 724, 726, 729, 732, 742, 745, 747, 752, 753, 755, 758, 760, 762, 766, 774, 780, 781, 784, 786, 787, 792, 798, 799, 801, 803, 804, 805, 809, 811, 815, 817, 820, 825]\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[33, 34, 39, 106, 162, 207, 328, 357, 610, 641, 642, 654, 657]\n"
     ]
    }
   ],
   "source": [
    "MiniRocketWindows = GenerateWindowsTest(5, \"MiniRocket\", 50, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[0, 7, 8, 9, 19, 23, 34, 36, 42, 49, 61, 64, 67, 106, 120, 126, 133, 135, 136, 139, 140, 142, 145, 158, 160, 162, 164, 165, 166, 175, 179, 181, 182, 185, 198, 204, 205, 207, 208, 212, 213, 218, 219, 223, 224, 229, 242, 251, 260, 274, 283, 286, 291, 294, 296, 300, 308, 314, 318, 321, 329, 340, 341, 352, 353, 355, 357, 358, 359, 364, 365, 369, 377, 381, 382, 384, 385, 389, 394, 415, 416, 418, 420, 421, 431, 432, 437, 447, 466, 472, 473, 476, 520, 523, 527, 530, 532, 536, 537, 539, 545, 546, 547, 553, 555, 580, 586, 587, 592, 593, 597, 603, 613, 615, 620, 623, 630, 634, 637, 638, 641, 642, 643, 644, 645, 651, 653, 654, 657, 664, 667, 668, 684, 685, 698, 709, 711, 720, 725, 729, 733, 734, 739, 743, 744, 773, 774, 775, 780, 783, 789, 792, 793, 794, 798, 800, 801, 802, 808, 811, 812, 816, 820, 821, 823, 825]\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[9, 34, 139, 145, 158, 175, 218, 291, 340, 352, 355, 358, 385, 437, 537, 613, 641, 651, 654, 657, 709, 780, 793, 794]\n",
      "Run 2\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[7, 9, 22, 31, 33, 48, 49, 51, 54, 57, 58, 82, 86, 90, 92, 107, 116, 126, 140, 142, 152, 153, 157, 159, 160, 161, 162, 165, 171, 177, 185, 192, 201, 207, 217, 225, 229, 230, 232, 239, 242, 243, 250, 251, 272, 276, 278, 304, 308, 316, 320, 321, 322, 338, 339, 340, 350, 351, 352, 357, 369, 375, 377, 379, 381, 384, 385, 392, 394, 407, 413, 418, 434, 435, 436, 437, 449, 468, 469, 472, 473, 475, 480, 481, 492, 493, 508, 514, 530, 537, 539, 557, 560, 563, 571, 574, 576, 580, 584, 585, 588, 589, 593, 596, 600, 602, 607, 618, 627, 628, 630, 641, 642, 654, 662, 671, 676, 686, 687, 700, 714, 720, 723, 724, 727, 733, 734, 736, 738, 751, 752, 758, 766, 767, 768, 777, 779, 780, 783, 790, 797, 798, 805, 806, 807, 817, 823, 824]\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[49, 58, 161, 165, 201, 242, 357, 375, 584, 585, 627, 727, 733]\n",
      "Run 3\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[6, 23, 48, 53, 55, 57, 61, 72, 73, 88, 91, 119, 123, 127, 140, 142, 161, 162, 164, 168, 175, 179, 184, 197, 202, 216, 222, 226, 231, 232, 240, 242, 243, 245, 252, 256, 257, 258, 259, 264, 281, 296, 301, 306, 314, 318, 320, 324, 326, 328, 353, 357, 358, 361, 365, 366, 375, 381, 387, 396, 407, 420, 421, 434, 446, 452, 477, 480, 492, 493, 503, 510, 514, 536, 543, 547, 552, 553, 558, 570, 572, 574, 589, 590, 593, 599, 603, 610, 614, 627, 632, 633, 634, 636, 641, 642, 644, 646, 650, 651, 654, 657, 658, 670, 673, 680, 681, 686, 690, 695, 699, 709, 715, 718, 724, 739, 743, 745, 756, 766, 767, 777, 789, 796, 802, 804, 805, 811, 822]\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[57, 161, 164, 232, 245, 256, 314, 318, 326, 328, 353, 558, 658, 690, 789]\n",
      "Run 4\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[5, 6, 10, 23, 25, 30, 33, 34, 35, 39, 47, 49, 56, 57, 59, 68, 77, 87, 91, 92, 105, 106, 109, 118, 120, 124, 127, 128, 140, 144, 146, 156, 161, 162, 164, 165, 166, 172, 175, 183, 193, 195, 200, 208, 209, 221, 222, 223, 225, 228, 232, 239, 242, 245, 246, 248, 251, 256, 264, 271, 272, 283, 294, 300, 304, 306, 329, 341, 347, 349, 350, 352, 355, 358, 360, 366, 369, 375, 377, 378, 379, 384, 385, 386, 388, 405, 416, 429, 430, 433, 439, 450, 465, 480, 485, 486, 487, 500, 519, 521, 524, 525, 529, 532, 536, 537, 540, 546, 551, 557, 570, 577, 582, 614, 615, 617, 618, 627, 632, 633, 634, 639, 640, 642, 643, 648, 654, 657, 665, 670, 682, 683, 690, 695, 696, 700, 709, 710, 711, 712, 717, 718, 727, 732, 733, 738, 742, 748, 755, 761, 770, 772, 773, 780, 785, 790, 791, 792, 793, 794, 796, 797, 802, 805, 815, 816, 819, 822]\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[33, 34, 49, 172, 175, 193, 208, 242, 251, 294, 306, 341, 358, 360, 369, 379, 521, 551, 617, 642, 643, 648, 654, 727, 733, 738, 780, 794]\n",
      "Run 5\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[0, 1, 6, 23, 33, 34, 52, 58, 60, 68, 76, 77, 87, 99, 101, 105, 112, 118, 124, 128, 138, 139, 140, 148, 150, 164, 165, 199, 203, 208, 211, 218, 223, 231, 232, 233, 243, 245, 257, 264, 283, 284, 291, 300, 303, 304, 309, 314, 318, 329, 330, 339, 341, 345, 347, 353, 354, 362, 364, 365, 376, 377, 384, 394, 398, 399, 400, 407, 412, 413, 418, 429, 430, 431, 449, 461, 485, 486, 504, 510, 518, 523, 524, 525, 529, 533, 536, 540, 544, 547, 550, 558, 560, 574, 585, 595, 603, 605, 607, 613, 614, 616, 619, 639, 641, 642, 644, 645, 661, 677, 684, 687, 689, 690, 692, 702, 704, 714, 725, 727, 733, 735, 738, 742, 745, 748, 756, 758, 774, 780, 781, 782, 783, 785, 788, 794, 802, 818]\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[1, 34, 58, 128, 208, 232, 243, 384, 398, 431, 735, 738, 756, 780]\n",
      "Run 1\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[8, 9, 20, 26, 31, 33, 34, 44, 47, 59, 72, 76, 77, 92, 93, 100, 103, 104, 106, 111, 118, 127, 132, 135, 136, 139, 142, 144, 148, 158, 162, 168, 171, 184, 192, 193, 197, 198, 201, 208, 217, 232, 245, 246, 247, 263, 264, 283, 317, 322, 335, 336, 337, 338, 342, 352, 353, 357, 358, 376, 379, 381, 387, 389, 390, 393, 394, 400, 411, 426, 430, 455, 471, 472, 473, 493, 509, 510, 530, 531, 538, 547, 558, 607, 608, 612, 617, 620, 621, 627, 634, 639, 645, 647, 648, 650, 653, 654, 657, 671, 672, 674, 675, 678, 680, 682, 683, 692, 714, 720, 725, 732, 733, 735, 737, 738, 741, 747, 753, 761, 777, 780, 784, 790, 791, 792, 802, 807]\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[20, 59, 77, 139, 142, 193, 201, 264, 283, 335, 430, 493, 547, 620, 654, 657, 733, 735, 738, 780, 802]\n",
      "Run 2\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[15, 18, 20, 21, 33, 34, 35, 46, 48, 49, 58, 59, 86, 93, 128, 137, 142, 145, 161, 165, 177, 178, 185, 198, 200, 215, 216, 266, 273, 292, 300, 302, 316, 328, 330, 339, 369, 374, 377, 394, 405, 430, 505, 506, 510, 511, 515, 543, 555, 559, 560, 564, 568, 583, 584, 586, 587, 602, 609, 613, 620, 624, 627, 652, 654, 668, 671, 673, 680, 692, 702, 703, 704, 716, 717, 741, 742, 753, 761, 767, 773, 780, 781, 784, 815]\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[33, 34, 58, 59, 86, 93, 185, 328, 369, 377, 430, 506, 560, 620, 780]\n",
      "Run 3\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[6, 7, 8, 11, 18, 33, 34, 39, 40, 49, 52, 68, 80, 91, 92, 93, 106, 109, 113, 123, 124, 129, 141, 150, 152, 153, 154, 159, 160, 161, 178, 196, 199, 200, 207, 212, 232, 233, 234, 243, 244, 247, 250, 260, 262, 280, 284, 287, 297, 298, 299, 300, 302, 304, 311, 317, 321, 325, 326, 327, 344, 345, 348, 349, 350, 357, 358, 376, 377, 378, 383, 388, 389, 390, 393, 402, 407, 412, 413, 418, 440, 448, 451, 453, 455, 468, 472, 479, 494, 495, 499, 504, 505, 517, 518, 521, 522, 534, 536, 540, 546, 554, 556, 562, 563, 568, 569, 579, 580, 585, 586, 593, 595, 596, 599, 609, 614, 616, 621, 623, 629, 631, 646, 653, 657, 661, 662, 670, 671, 675, 678, 688, 689, 692, 702, 715, 716, 718, 724, 725, 737, 738, 742, 743, 747, 755, 761, 763, 785, 788, 790, 791, 792, 793, 797, 798, 800, 802, 803, 807, 808, 810, 812, 823, 825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[49, 92, 141, 161, 232, 243, 247, 505, 546, 586, 595, 646, 657, 678, 689, 724, 725, 737]\n",
      "Run 4\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[10, 15, 25, 34, 50, 56, 57, 60, 61, 63, 77, 84, 105, 112, 114, 119, 122, 127, 142, 153, 164, 165, 166, 168, 177, 178, 184, 187, 189, 191, 193, 196, 203, 204, 205, 208, 224, 226, 235, 243, 245, 256, 264, 265, 272, 285, 287, 290, 291, 293, 300, 314, 319, 322, 323, 324, 328, 330, 333, 334, 341, 344, 346, 352, 357, 361, 365, 367, 373, 374, 394, 405, 417, 420, 428, 430, 447, 448, 454, 460, 462, 470, 473, 477, 485, 490, 491, 492, 496, 497, 499, 505, 510, 511, 514, 516, 521, 527, 530, 552, 560, 563, 569, 571, 572, 574, 592, 596, 600, 603, 607, 608, 609, 611, 616, 625, 628, 629, 632, 633, 634, 641, 642, 643, 645, 651, 654, 657, 666, 671, 672, 673, 684, 689, 704, 711, 724, 725, 731, 733, 735, 737, 741, 744, 748, 752, 756, 758, 767, 780, 781, 782, 791, 792, 793, 797, 814, 818, 822, 824]\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[15, 34, 243, 245, 256, 293, 319, 430, 485, 510, 511, 654, 689, 733, 744, 758, 797]\n",
      "Run 5\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[8, 9, 15, 16, 18, 19, 23, 34, 53, 62, 68, 69, 78, 79, 100, 101, 107, 112, 119, 128, 141, 143, 148, 149, 158, 160, 162, 164, 165, 166, 172, 179, 185, 186, 189, 193, 198, 200, 201, 205, 208, 226, 232, 234, 242, 247, 249, 253, 281, 282, 283, 290, 295, 298, 302, 309, 318, 326, 327, 334, 335, 336, 342, 345, 348, 351, 357, 358, 365, 370, 376, 380, 384, 386, 393, 394, 396, 398, 405, 422, 423, 430, 449, 457, 465, 466, 470, 471, 472, 479, 484, 485, 487, 495, 504, 508, 511, 521, 532, 537, 539, 546, 547, 555, 556, 557, 562, 575, 576, 584, 586, 595, 599, 606, 607, 613, 620, 624, 626, 631, 643, 647, 650, 654, 702, 709, 715, 723, 724, 725, 727, 729, 733, 734, 735, 738, 739, 744, 747, 748, 751, 756, 767, 771, 774, 780, 784, 787, 792, 796, 798, 802, 807, 808, 810, 811, 813, 817, 822]\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[15, 23, 34, 128, 158, 165, 242, 430, 555, 620, 626, 650, 733, 756, 798]\n"
     ]
    }
   ],
   "source": [
    "MrSEQLWindows = GenerateWindowsTest(5, \"MrSEQL\", 50, 0.6)\n",
    "RandomForestWindows = GenerateWindowsTest(5, \"RandomForest\", 50, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1650-1700', 4),\n",
       " ('1700-1750', 4),\n",
       " ('32050-32100', 4),\n",
       " ('6400-6450', 2),\n",
       " ('8850-8900', 2)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MiniRocketWindows[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1700-1750', 3),\n",
       " ('39000-39050', 3),\n",
       " ('8750-8800', 2),\n",
       " ('17900-17950', 2),\n",
       " ('32700-32750', 2)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MrSEQLWindows[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('21500-21550', 4),\n",
       " ('31000-31050', 3),\n",
       " ('36650-36700', 3),\n",
       " ('1700-1750', 3),\n",
       " ('2950-3000', 2)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestWindows[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs11127780</th>\n",
       "      <th>rs10865598</th>\n",
       "      <th>rs2317203</th>\n",
       "      <th>rs2085079</th>\n",
       "      <th>rs6806513</th>\n",
       "      <th>rs716764</th>\n",
       "      <th>rs716763</th>\n",
       "      <th>rs6785245</th>\n",
       "      <th>rs834854</th>\n",
       "      <th>rs1869517</th>\n",
       "      <th>...</th>\n",
       "      <th>rs9875881</th>\n",
       "      <th>rs17020227</th>\n",
       "      <th>rs1995065</th>\n",
       "      <th>rs6803059</th>\n",
       "      <th>rs13075335</th>\n",
       "      <th>rs6791124</th>\n",
       "      <th>rs9309915</th>\n",
       "      <th>rs9867035</th>\n",
       "      <th>rs2029918</th>\n",
       "      <th>rs9872847</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rs11127780  rs10865598  rs2317203  rs2085079  rs6806513  rs716764  \\\n",
       "0             0           2          0          2          0         2   \n",
       "1             1           2          0          1          1         2   \n",
       "2             0           2          0          2          0         2   \n",
       "3             1           1          1          1          1         2   \n",
       "4             2           1          1          1          1         2   \n",
       "..          ...         ...        ...        ...        ...       ...   \n",
       "104           2           1          2          1          2         1   \n",
       "105           1           1          1          1          1         2   \n",
       "106           1           1          1          0          2         2   \n",
       "107           1           1          1          1          1         2   \n",
       "108           1           2          1          1          1         2   \n",
       "\n",
       "     rs716763  rs6785245  rs834854  rs1869517  ...  rs9875881  rs17020227  \\\n",
       "0           0          0         0          1  ...          1           2   \n",
       "1           1          1         1          1  ...          1           2   \n",
       "2           0          0         0          1  ...          1           1   \n",
       "3           1          1         1          1  ...          1           1   \n",
       "4           1          1         1          1  ...          2           2   \n",
       "..        ...        ...       ...        ...  ...        ...         ...   \n",
       "104         2          2         2          2  ...          1           2   \n",
       "105         1          1         1          1  ...          2           2   \n",
       "106         2          2         2          2  ...          1           1   \n",
       "107         1          1         1          1  ...          2           2   \n",
       "108         1          1         1          1  ...          0           1   \n",
       "\n",
       "     rs1995065  rs6803059  rs13075335  rs6791124  rs9309915  rs9867035  \\\n",
       "0            1          1           2          1          2          1   \n",
       "1            1          1           2          1          2          1   \n",
       "2            2          1           1          1          1          2   \n",
       "3            1          1           1          1          1          2   \n",
       "4            1          2           2          2          2          2   \n",
       "..         ...        ...         ...        ...        ...        ...   \n",
       "104          1          1           2          1          2          1   \n",
       "105          0          2           2          2          2          2   \n",
       "106          1          1           1          1          1          2   \n",
       "107          0          2           2          2          2          2   \n",
       "108          2          0           1          0          1          1   \n",
       "\n",
       "     rs2029918  rs9872847  \n",
       "0            1          1  \n",
       "1            1          1  \n",
       "2            1          2  \n",
       "3            1          1  \n",
       "4            2          1  \n",
       "..         ...        ...  \n",
       "104          1          1  \n",
       "105          2          0  \n",
       "106          1          1  \n",
       "107          2          0  \n",
       "108          0          2  \n",
       "\n",
       "[109 rows x 100 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.iloc[:, 1650:1750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for RandomForest on selected SNP window: 0.5727272727272729\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using RandomForest\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTtest, yTrain, yTest = train_test_split(dfTest.iloc[:, 21500:21550], phenotype, train_size=0.7)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredicted = rfc.predict(xTtest)\n",
    "    results.append(accuracy_score(yTest, yPredicted))\n",
    "    \n",
    "print(f\"Average accuracy for RandomForest on selected SNP window: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MiniRocket on selected SNP window: 0.7363636363636364\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTest.iloc[:, np.r_[1650:1750,32050:32100]], phenotype, train_size=0.7)\n",
    "\n",
    "    \n",
    "    xTrain = from_2d_array_to_nested(xTrain)\n",
    "    xTest = from_2d_array_to_nested(xTest)\n",
    "    \n",
    "    minirocket = MiniRocket()\n",
    "    minirocket.fit(xTrain)\n",
    "    xTrainTransform = minirocket.transform(xTrain)\n",
    "\n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "\n",
    "    xTestTransform = minirocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MiniRocket on selected SNP window: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MrSEQL on selected SNP window: 0.6454545454545456\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTest.iloc[:, 1700:1750], phenotype, train_size=0.7)\n",
    "    \n",
    "    xTrain = from_2d_array_to_nested(xTrain)\n",
    "    xTest = from_2d_array_to_nested(xTest)\n",
    "    \n",
    "    ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "    ms.fit(xTrain, yTrain)\n",
    "    yPredict = ms.predict(xTest)\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MrSEQL on selected SNP window: {sum(results) / len(results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
