{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC  \n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.datasets import load_arrow_head, load_basic_motions\n",
    "\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from sktime.datasets import load_arrow_head \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening up file containing GWAS data and reading in\n",
    "\n",
    "file = open(\"GWAS_Add.raw\", \"r\")\n",
    "lines = file.readlines()\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GWAS data into DF in the correct format\n",
    "\n",
    "columns = lines[0].strip(\"\\n\").split(\" \")\n",
    "columns = [n.split(\"_\", 1)[0] for n in columns]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "i = 1\n",
    "data = []\n",
    "for line in lines[1:]:\n",
    "    newRow = line.strip(\"\\n\").split(\" \")\n",
    "    for position in range(0, len(newRow)):\n",
    "        if newRow[position] == \"0\":\n",
    "            newRow[position] = \"2\"\n",
    "        elif newRow[position] == \"2\":\n",
    "            newRow[position] = \"0\"\n",
    "        \n",
    "    data.append(newRow)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to see if control SNPs have been encoded correctly\n",
    "\n",
    "df1 = df[[\"rs2222162\",\"PHENOTYPE\"]]\n",
    "df1[df1[\"PHENOTYPE\"] == \"1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to see if cases SNPs have been encoded correctly\n",
    "\n",
    "df1 = df[[\"rs2222162\",\"PHENOTYPE\"]]\n",
    "df1[df1[\"PHENOTYPE\"] == \"0\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only selecting 100 SNPs located on chromosome 2 \n",
    "\n",
    "dfAlleles = df.loc[:, \"rs11684739\":\"rs2521953\"]\n",
    "dfAllelesLarge = df.loc[:, \"rs11684739\":\"rs6757306\"]\n",
    "dfInfo = df.loc[:, :\"PHENOTYPE\"]\n",
    "df = dfInfo.join(dfAlleles)\n",
    "dfLarge = dfInfo.join(dfAllelesLarge)\n",
    "len(df.columns), len(dfLarge.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Phenotype values\n",
    "\n",
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"1\",\"control\")\n",
    "\n",
    "dfLarge[\"PHENOTYPE\"] = dfLarge[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "dfLarge[\"PHENOTYPE\"] = dfLarge[\"PHENOTYPE\"].replace(\"1\",\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSave = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-encoding SNP of interest to generate stronger signal\n",
    "\n",
    "#df.loc[df.PHENOTYPE == \"case\", [\"rs2222162\"]] = \"2\"\n",
    "#df.loc[df.PHENOTYPE == \"control\", [\"rs2222162\"]] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ID columns and \n",
    "\n",
    "phenotype = df.pop(\"PHENOTYPE\")\n",
    "dfTest = df.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "dfTestLarge = dfLarge.drop(columns=[\"PHENOTYPE\",\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing SNP entries and replacing with most frequent value for that SNP of other entries\n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idf = pd.DataFrame(imp.fit_transform(dfTest))\n",
    "idf.columns = dfTest.columns\n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idfLarge = pd.DataFrame(imp.fit_transform(dfTestLarge))\n",
    "idfLarge.columns = dfTestLarge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to be numberical\n",
    "idf = idf.apply(pd.to_numeric)\n",
    "idfLarge = idfLarge.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLargeSave = idfLarge.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting index of SNP of interest\n",
    "idfT = idf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 0 - control\n",
    "position = idfT[0].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[0][0:position+1], color=\"tab:blue\")\n",
    "plt.plot(idfT[0][position-1:position+1], color=\"red\")\n",
    "plt.plot(idfT[0][position:],color=\"tab:blue\")\n",
    "phenotype[0], idfT[0][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 8 - control\n",
    "\n",
    "position = idfT[8].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[8][0:position-1], color=\"tab:blue\")\n",
    "plt.plot(idfT[8][position-2:position+1], color=\"red\")\n",
    "plt.plot(idfT[8][position:],color=\"tab:blue\")\n",
    "phenotype[8], idfT[8][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 2 - case\n",
    "\n",
    "position = idfT[2].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[2][0:position], color=\"tab:blue\")\n",
    "plt.plot(idfT[2][position-1:position+1], color=\"red\")\n",
    "plt.plot(idfT[2][position:],color=\"tab:blue\")\n",
    "phenotype[2], idfT[2][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising entry 88 - case\n",
    "\n",
    "position = idfT[88].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[88][0:position], color=\"tab:blue\")\n",
    "plt.plot(idfT[88][position-1:position+1], color=\"red\")\n",
    "plt.plot(idfT[88][position:],color=\"tab:blue\")\n",
    "phenotype[88], idfT[88][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training data and testing data\n",
    "\n",
    "xTrain, xTtest, yTrain, yTest = train_test_split(idf, phenotype, train_size=0.6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for RandomForst\n",
    "\n",
    "# bootstrap = [True, False]\n",
    "# maxDepth = list(range(10,110,10))\n",
    "# maxFeatures = [\"auto\", \"sqrt\"]\n",
    "# minSamplesLeaf = [1,2,3,4]\n",
    "# minSamplesSplit = [2,3,5]\n",
    "# nEstimators = list(range(100,1100,100))\n",
    "\n",
    "# hyperparameters = dict(bootstrap=bootstrap, max_depth=maxDepth, max_features=maxFeatures, min_samples_leaf=minSamplesLeaf,\n",
    "#                       min_samples_split=minSamplesSplit, n_estimators=nEstimators)\n",
    "\n",
    "# rfd = RandomForestClassifier()\n",
    "\n",
    "# clf = GridSearchCV(rfd, hyperparameters, cv=10)\n",
    "\n",
    "# bestModel = clf.fit(idf, phenotype)\n",
    "# print('Best bootstrap:', bestModel.best_estimator_.get_params()['bootstrap'])\n",
    "# print('Best max_depth:', bestModel.best_estimator_.get_params()['max_depth'])\n",
    "# print('Best max_features:', bestModel.best_estimator_.get_params()['max_features'])\n",
    "# print('Best min_samples_leaf:', bestModel.best_estimator_.get_params()['min_samples_leaf'])\n",
    "# print('Best min_samples_split:', bestModel.best_estimator_.get_params()['min_samples_split'])\n",
    "# print('Best n_estimators:', bestModel.best_estimator_.get_params()['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using decision tree and printing results\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True, max_depth=100, max_features=\"sqrt\", \n",
    "                             min_samples_leaf=4, min_samples_split=2, n_estimators=100)\n",
    "rfc.fit(xTrain, yTrain)\n",
    "yPredicted = rfc.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = rfc.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))\n",
    "print(classification_report(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting features that random forest classifier found important\n",
    "\n",
    "rf =  pd.DataFrame({\"featrue\": idf.columns, \"importance\":rfc.feature_importances_})\n",
    "sorted_idx = rfc.feature_importances_.argsort()\n",
    "plt.barh(idf.columns[sorted_idx[-10:]], rfc.feature_importances_[sorted_idx[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for KNN\n",
    "\n",
    "\n",
    "# leafSize = list(range(1,30))\n",
    "# neighbours = list(range(1,30))\n",
    "# p = [1,2]\n",
    "# hyperparameters = dict(leaf_size=leafSize, n_neighbors=neighbours, p=p)\n",
    "\n",
    "# knn = KNeighborsClassifier() \n",
    "\n",
    "# clf = GridSearchCV(knn, hyperparameters, cv=10)\n",
    "\n",
    "# bestModel = clf.fit(idf, phenotype)\n",
    "# print('Best leaf_size:', bestModel.best_estimator_.get_params()['leaf_size'])\n",
    "# print('Best p:', bestModel.best_estimator_.get_params()['p'])\n",
    "# print('Best n_neighbors:', bestModel.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using KNN and printing results\n",
    "\n",
    "knnClf = KNeighborsClassifier(leaf_size=1, n_neighbors=22,p=2 ) \n",
    "knnClf.fit(xTrain, yTrain)\n",
    "yPredicted = knnClf.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = knnClf.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding hyperparameters for KNN\n",
    "\n",
    "# C = [0.1,1, 10, 100]\n",
    "# gamma = [1,0.1,0.01,0.001]\n",
    "# kernel = ['rbf', 'poly', 'sigmoid']\n",
    "# hyperparameters = dict(C=C,gamma=gamma,kernel=kernel)\n",
    "\n",
    "# SVM = SVC()\n",
    "\n",
    "# clf = GridSearchCV(SVM, hyperparameters, refit=True,cv=10)\n",
    "\n",
    "# bestModel = clf.fit(idf, phenotype)\n",
    "# print('Best C:', bestModel.best_estimator_.get_params()['C'])\n",
    "# print('Best gamma:', bestModel.best_estimator_.get_params()['gamma'])\n",
    "# print('Best kernel:', bestModel.best_estimator_.get_params()['kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using sigmoid SVC and printing results\n",
    "\n",
    "SVM = SVC(kernel=\"sigmoid\", C=100, gamma=0.001)\n",
    "SVM.fit(xTrain, yTrain)\n",
    "yPredicted = SVM.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = SVM.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using sigmoid SVC and printing results\n",
    "\n",
    "RCLF = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "RCLF.fit(xTrain, yTrain)\n",
    "yPredicted = RCLF.predict(xTrain)\n",
    "print(\"Training accuracy score: {}\".format(accuracy_score(yTrain, yPredicted)))\n",
    "yPredicted = RCLF.predict(xTtest)\n",
    "print(\"Testing accuracy score: {}\".format(accuracy_score(yTest, yPredicted)))\n",
    "print(confusion_matrix(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting df columns into 2d numpy array time series\n",
    "\n",
    "idf = idf.apply(pd.to_numeric)\n",
    "idfSeries = from_2d_array_to_nested(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting time seriesdata into training data and testing data\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from training split\n",
    "\n",
    "yTrain = yTrain.values\n",
    "yTest = yTest.values\n",
    "\n",
    "xTrain = xTrain.reset_index()\n",
    "xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "xTest = xTest.reset_index()\n",
    "xTest = xTest.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running rocket kernal transformation on training data\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(xTrain)\n",
    "xTrainTransform = rocket.transform(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS Data from rocket transformation using Ridge Classifier\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "classifier.fit(xTrainTransform, yTrain)\n",
    "xTestTransform = rocket.transform(xTest)\n",
    "yPredict = classifier.predict(xTestTransform)\n",
    "print(\"Accuracy with Rocket: %2.3f\" % metrics.accuracy_score(yTest, yPredict))\n",
    "print(confusion_matrix(yTest, yPredict))\n",
    "print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifying GWAS data using MrSEQL\n",
    "\n",
    "ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "ms.fit(xTrain, yTrain)\n",
    "yPredict = ms.predict(xTest)\n",
    "print(\"Accuracy with MrSEQL: %2.3f\" % metrics.accuracy_score(yTest, yPredict))\n",
    "print(confusion_matrix(yTest, yPredict))\n",
    "print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to setup df for testing\n",
    "\n",
    "def SetupTest(df):\n",
    "    \n",
    "    imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "    idf = pd.DataFrame(imp.fit_transform(df))\n",
    "    idf.columns = df.columns\n",
    "    idf = idf.apply(pd.to_numeric)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to generate graph that displays change in accuracy for a given classifier as the length of the target SNP\n",
    "#    is increased\n",
    "\n",
    "def GenerateSignalGraph(df, classifier):\n",
    "    \n",
    "    results = []\n",
    "    dfTest = df.copy(deep=True)\n",
    "    phenotype = dfTest.pop(\"PHENOTYPE\")\n",
    "    dfTest = dfTest.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "    for n in range(1,10):\n",
    "        classifierTemp = clone(classifier)\n",
    "        dfTest.insert(dfTest.columns.get_loc(\"rs2222162\"), f\"rs222216_{n}\", dfTest[\"rs2222162\"])\n",
    "        idf = SetupTest(dfTest)\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(idf, phenotype, train_size=0.6, random_state=1)\n",
    "        classifierTemp.fit(xTrain, yTrain)\n",
    "        yPredict = classifierTemp.predict(xTest)\n",
    "        results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "        \n",
    "        if n == 9:\n",
    "            print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "            print(confusion_matrix(yTest, yPredict))\n",
    "            print(classification_report(yTest, yPredict))\n",
    "            \n",
    "    plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for Random Forst\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True, max_depth=100, max_features=\"sqrt\", \n",
    "                             min_samples_leaf=4, min_samples_split=2, n_estimators=100)\n",
    "GenerateSignalGraph(dfSave, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for Knn\n",
    "\n",
    "knnClf = KNeighborsClassifier(leaf_size=1, n_neighbors=22,p=2 ) \n",
    "GenerateSignalGraph(dfSave, knnClf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting change in accuracy for increased signal length for SVM\n",
    "\n",
    "SVM = SVC(kernel=\"sigmoid\", C=100, gamma=0.001)\n",
    "GenerateSignalGraph(dfSave, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCLF = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "GenerateSignalGraph(dfSave, RCLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "dfTest = dfSave.copy(deep=True)\n",
    "phenotype = dfTest.pop(\"PHENOTYPE\")\n",
    "dfTest = dfTest.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "\n",
    "for n in range(1,10):\n",
    "    \n",
    "    dfTest.insert(dfTest.columns.get_loc(\"rs2222162\"), f\"rs222216_{n}\", dfTest[\"rs2222162\"])\n",
    "    idf = SetupTest(dfTest)\n",
    "    idfSeries = from_2d_array_to_nested(idf)\n",
    "    \n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    \n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "\n",
    "    xTrain = xTrain.reset_index()\n",
    "    xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "    xTest = xTest.reset_index()\n",
    "    xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "    rocket = Rocket()\n",
    "    rocket.fit(xTrain)\n",
    "    xTrainTransform = rocket.transform(xTrain)\n",
    "    \n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "    xTestTransform = rocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "    results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "    \n",
    "    if n == 9:\n",
    "        \n",
    "        print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "        print(confusion_matrix(yTest, yPredict))\n",
    "        print(classification_report(yTest, yPredict))\n",
    "    \n",
    "    \n",
    "_ = plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "dfTest = dfSave.copy(deep=True)\n",
    "phenotype = dfTest.pop(\"PHENOTYPE\")\n",
    "dfTest = dfTest.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])\n",
    "idf=None\n",
    "for n in range(1,10):\n",
    "    \n",
    "    dfTest.insert(dfTest.columns.get_loc(\"rs2222162\"), f\"rs2222162_{n}\", dfTest[\"rs2222162\"])\n",
    "    idf = SetupTest(dfTest)\n",
    "    idfSeries = from_2d_array_to_nested(idf)\n",
    "    \n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    \n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "\n",
    "    xTrain = xTrain.reset_index()\n",
    "    xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "    xTest = xTest.reset_index()\n",
    "    xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "    ms = MrSEQLClassifier(seql_mode=\"fs\")\n",
    "    ms.fit(xTrain, yTrain)\n",
    "    yPredict = ms.predict(xTest)\n",
    "    results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "    \n",
    "    if n == 9:\n",
    "        print(f\"Accuracy with 10 length signal: {metrics.accuracy_score(yTest, yPredict)}\")\n",
    "        print(confusion_matrix(yTest, yPredict))\n",
    "        print(classification_report(yTest, yPredict))\n",
    "    \n",
    "_ = plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfT = idf.T\n",
    "position = idfT[8].index.get_loc(\"rs2222162\")\n",
    "plt.xticks([])\n",
    "plt.plot(idfT[8][0:position-1], color=\"tab:blue\")\n",
    "plt.plot(idfT[8][position-2:position+1], color=\"red\")\n",
    "plt.plot(idfT[8][position:],color=\"tab:blue\")\n",
    "phenotype[position], idfT[8][position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfT[8].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,10):\n",
    "    \n",
    "    idfLarge.insert(idfLarge.columns.get_loc(\"rs2222162\"), f\"rs2222162_{n}\", idfLarge[\"rs2222162\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for index in range(109,610):\n",
    "    print(f\"current run {index-108}\")\n",
    "    currentDf = idfLarge.iloc[:, 0:index]\n",
    "    idf = currentDf.apply(pd.to_numeric)\n",
    "    idfSeries = from_2d_array_to_nested(idf)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(idfSeries, phenotype, train_size=0.6, random_state=1)\n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "\n",
    "    xTrain = xTrain.reset_index()\n",
    "    xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "    xTest = xTest.reset_index()\n",
    "    xTest = xTest.drop(columns=[\"index\"])\n",
    "    \n",
    "    ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "    ms.fit(xTrain, yTrain)\n",
    "    yPredict = ms.predict(xTest)\n",
    "    \n",
    "    results.append(metrics.accuracy_score(yTest, yPredict))\n",
    "    \n",
    "_ = plt.plot(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
