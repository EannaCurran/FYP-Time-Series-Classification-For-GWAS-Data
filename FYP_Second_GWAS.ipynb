{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.transformations.panel.rocket import MiniRocket\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening up file containing GWAS data and reading in\n",
    "\n",
    "file = open(\"Second_GWAS/Second_GWAS_Add.raw\", \"r\")\n",
    "lines = file.readlines()\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GWAS data into DF in the correct format\n",
    "\n",
    "columns = lines[0].strip(\"\\n\").split(\" \")\n",
    "columns = [n.split(\"_\", 1)[0] for n in columns]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "data = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    newRow = line.strip(\"\\n\").split(\" \")\n",
    "    for position in range(0, len(newRow)):\n",
    "        if newRow[position] == \"0\":\n",
    "            newRow[position] = \"2\"\n",
    "        elif newRow[position] == \"2\":\n",
    "            newRow[position] = \"0\"\n",
    "        \n",
    "    data.append(newRow)\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55\n",
       "0    54\n",
       "Name: PHENOTYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see split between cases and controls\n",
    "\n",
    "df[\"PHENOTYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 41313)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing shape of df\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FID', 'IID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE', 'rs7433861',\n",
       "       'rs1166974', 'rs1166975', 'rs10446372',\n",
       "       ...\n",
       "       'rs4030335', 'rs7374010', 'rs9877345', 'rs7373662', 'rs12630742',\n",
       "       'rs11916265', 'rs7374354', 'rs9325418', 'rs9325420', 'rs10154902'],\n",
       "      dtype='object', length=41313)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing shape of df\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"0\",\"case\")\n",
    "df[\"PHENOTYPE\"] = df[\"PHENOTYPE\"].replace(\"1\",\"control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns and seperating phenotype column\n",
    "phenotype = df.pop(\"PHENOTYPE\")\n",
    "dfTest = df.drop(columns=[\"FID\",\"IID\",\"PAT\",\"MAT\",\"SEX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in df with most common allele for \n",
    "\n",
    "imp = SimpleImputer(missing_values=\"NA\", strategy=\"most_frequent\")\n",
    "idf = pd.DataFrame(imp.fit_transform(dfTest))\n",
    "idf.columns = dfTest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to be numberical\n",
    "\n",
    "dfTest = idf.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'case'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising first 100 SNPs of first case\n",
    "\n",
    "dfTranspose = dfTest.T\n",
    "plt.xticks([])\n",
    "plt.plot(dfTranspose[0][0:100], color=\"tab:blue\")\n",
    "phenotype[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training data and testing data\n",
    "\n",
    "xTrain, xTtest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for RandomForest on entire dataset: 0.5424242424242424\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using RandomForest\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTtest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredicted = rfc.predict(xTtest)\n",
    "    results.append(accuracy_score(yTest, yPredicted))\n",
    "    \n",
    "print(f\"Average accuracy for RandomForest on entire dataset: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting df to array structure\n",
    "\n",
    "dfTestSeries = from_2d_array_to_nested(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting time series data into training data and testing data\n",
    "\n",
    "#xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from training split\n",
    "\n",
    "#yTrain = yTrain.values\n",
    "#yTest = yTest.values\n",
    "\n",
    "#xTrain = xTrain.reset_index()\n",
    "#xTrain = xTrain.drop(columns=[\"index\"])\n",
    "\n",
    "#xTest = xTest.reset_index()\n",
    "#xTest = xTest.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MiniRocket on entire dataset: 0.4545454545454545\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using MiniRocket\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.7)\n",
    "    minirocket = MiniRocket()\n",
    "    minirocket.fit(xTrain)\n",
    "    xTrainTransform = minirocket.transform(xTrain)\n",
    "\n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "\n",
    "    xTestTransform = minirocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MiniRocket on entire dataset: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNPS = ['rs9867035', 'rs7638693', 'rs9837776', 'rs2873392', 'rs6792542',\n",
    "       'rs1600058', 'rs1580295', 'rs1316579', 'rs834856', 'rs7430111',\n",
    "       'rs9817983', 'rs2085079', 'rs834858', 'rs834843', 'rs834864',\n",
    "       'rs9855684', 'rs1598120', 'rs6445172', 'rs9853565', 'rs1097157']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for RandomForest on selected SNPs: 0.8181818181818181\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using RandomForest\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTtest, yTrain, yTest = train_test_split(dfTest[SNPS], phenotype, train_size=0.7)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredicted = rfc.predict(xTtest)\n",
    "    results.append(accuracy_score(yTest, yPredicted))\n",
    "    \n",
    "print(f\"Average accuracy for RandomForest on selected SNPs: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestSeries = from_2d_array_to_nested(dfTest[SNPS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MiniRocket on selected SNPs: 0.7696969696969698\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using MiniRocket\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTestSeries, phenotype, train_size=0.7)\n",
    "    minirocket = MiniRocket()\n",
    "    minirocket.fit(xTrain)\n",
    "    xTrainTransform = minirocket.transform(xTrain)\n",
    "\n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "\n",
    "    xTestTransform = minirocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MiniRocket on selected SNPs: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying GWAS data using MrSEQL\n",
    "\n",
    "#ms = MrSEQLClassifier(seql_mode=\"fs\")\n",
    "\n",
    "#ms.fit(xTrain, yTrain)\n",
    "#yPredict = ms.predict(xTest)\n",
    "\n",
    "#print(\"Accuracy with MrSEQL: %2.3f\" % metrics.accuracy_score(yTest, yPredict))\n",
    "#print(confusion_matrix(yTest, yPredict))\n",
    "#print(classification_report(yTest, yPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def GenerateWindowsTest(runs, classifierType, windowSize, threshold):\n",
    "\n",
    "    results = {}\n",
    "    numberOfWindows = len(dfTest.columns) // windowSize\n",
    "    \n",
    "    for k in range(1,runs+1):\n",
    "\n",
    "        print(f\"Run {k}\")\n",
    "\n",
    "        validationScores = []\n",
    "        testScores = []\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(dfTest, phenotype, train_size=0.7)\n",
    "        xTrainSplit, xValidate, yTrainSplit, yValidate = train_test_split(xTrain, yTrain, train_size=0.7)\n",
    "\n",
    "        for n in range(0,numberOfWindows):\n",
    "\n",
    "            if(n%(numberOfWindows//10) == 0 and n != 0):\n",
    "                print(f\"Progress: {round((n/numberOfWindows) * 100)}%\")\n",
    "                \n",
    "            windowStart = n * windowSize\n",
    "            windowEnd = windowStart + windowSize\n",
    "            xTrainWindow = xTrainSplit.iloc[:,windowStart:windowEnd]\n",
    "            xValidateWindow = xValidate.iloc[:,windowStart:windowEnd]\n",
    "            \n",
    "            if classifierType == \"MiniRocket\":\n",
    "\n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xValidateWindowSeries = from_2d_array_to_nested(xValidateWindow)\n",
    "                minirocket = MiniRocket()\n",
    "                minirocket.fit(xTrainWindowSeries)\n",
    "                xTrainTransform = minirocket.transform(xTrainWindowSeries)\n",
    "                classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "                classifier.fit(xTrainTransform, yTrainSplit)\n",
    "                xValidateTransform = minirocket.transform(xValidateWindowSeries)\n",
    "                score = classifier.score(xValidateTransform, yValidate)\n",
    "            \n",
    "            elif  classifierType == \"MrSEQL\":\n",
    "                \n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xValidateWindowSeries = from_2d_array_to_nested(xValidateWindow)\n",
    "                ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "                ms.fit(xTrainWindowSeries, yTrainSplit)\n",
    "                yPredict = ms.predict(xValidateWindowSeries)\n",
    "                score = metrics.accuracy_score(yValidate, yPredict)\n",
    "            \n",
    "            elif classifierType == \"RandomForest\":\n",
    "                \n",
    "                rfc = RandomForestClassifier()\n",
    "                rfc.fit(xTrainWindow, yTrainSplit)\n",
    "                yPredict = rfc.predict(xValidateWindow)\n",
    "                score = metrics.accuracy_score(yValidate, yPredict)\n",
    "            \n",
    "            validationScores.append(score)\n",
    "\n",
    "        windowsAboveThreshold = [n for n in range(len(validationScores)) if validationScores[n] > threshold]\n",
    "        \n",
    "        print(f\"Window positions from validation with accuracy above threshold for run {k}\")\n",
    "        print(windowsAboveThreshold)\n",
    "\n",
    "        windowsAboveThresholdAfterTest = []\n",
    "\n",
    "        for n in windowsAboveThreshold:\n",
    "\n",
    "            windowStart = n * windowSize\n",
    "            windowEnd = windowStart + windowSize\n",
    "            xTrainWindow = xTrain.iloc[:,windowStart:windowEnd]\n",
    "            xTestWindow = xTest.iloc[:,windowStart:windowEnd]\n",
    "            \n",
    "            if classifierType == \"MiniRocket\":\n",
    "                \n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xTestWindowSeries = from_2d_array_to_nested(xTestWindow)\n",
    "                minirocket = MiniRocket()\n",
    "                minirocket.fit(xTrainWindowSeries)\n",
    "                xTrainTransform = minirocket.transform(xTrainWindowSeries)\n",
    "                classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "                classifier.fit(xTrainTransform, yTrain)\n",
    "                xTestTransform = minirocket.transform(xTestWindowSeries)\n",
    "                score = classifier.score(xTestTransform, yTest)\n",
    "                \n",
    "            elif  classifierType == \"MrSEQL\":\n",
    "                \n",
    "                xTrainWindowSeries = from_2d_array_to_nested(xTrainWindow)\n",
    "                xTestWindowSeries = from_2d_array_to_nested(xTestWindow)\n",
    "                ms = MrSEQLClassifier(seql_mode=\"clf\")\n",
    "                ms.fit(xTrainWindowSeries, yTrain)\n",
    "                yPredict = ms.predict(xTestWindowSeries)\n",
    "                score = metrics.accuracy_score(yTest, yPredict)\n",
    "            \n",
    "            elif classifierType == \"RandomForest\":\n",
    "                \n",
    "                rfc = RandomForestClassifier()\n",
    "                rfc.fit(xTrainWindow, yTrain)\n",
    "                yPredict = rfc.predict(xTestWindow)\n",
    "                score = metrics.accuracy_score(yTest, yPredict)\n",
    "                \n",
    "            testScores.append(score)\n",
    "\n",
    "                \n",
    "        windowsAboveThresholdAfterTest = [windowsAboveThreshold[n] for n in range(len(windowsAboveThreshold)) if testScores[n] > threshold]\n",
    "        \n",
    "        print(f\"Window positions from validation with accuracy above threshold for run {k}\")\n",
    "        print(windowsAboveThresholdAfterTest)\n",
    "\n",
    "        for window in windowsAboveThresholdAfterTest:\n",
    "            if window in results:\n",
    "                results[window] += 1\n",
    "            else:\n",
    "                results[window] = 1\n",
    "                \n",
    "    sortedResults = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    updatedKeyResults = {}\n",
    "    for key, value in results.items():\n",
    "        newKeyStart = key*windowSize\n",
    "        newKeyEnd = newKeyStart + windowSize\n",
    "        updatedKeyResults[f\"{newKeyStart}-{newKeyEnd}\"] = value\n",
    "        \n",
    "    sortedResults = sorted(updatedKeyResults.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sortedResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[14, 22, 23, 34, 35, 51, 66, 67, 93, 131, 140, 159, 160, 162, 163, 184, 198, 199, 215, 298, 319, 326, 340, 358, 375, 385, 420, 437, 440, 459, 470, 480, 510, 537, 547, 582, 611, 641, 642, 654, 688, 725, 733, 742, 758, 772, 779, 780, 782, 794]\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[34, 93, 140, 198, 326, 385, 537, 611, 725, 733, 780]\n",
      "Run 2\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[4, 8, 9, 10, 12, 19, 21, 32, 33, 34, 36, 50, 55, 57, 58, 62, 67, 85, 88, 89, 90, 93, 98, 105, 106, 119, 139, 140, 150, 154, 156, 168, 175, 177, 181, 182, 183, 184, 199, 200, 208, 209, 219, 220, 221, 222, 223, 224, 234, 239, 252, 260, 261, 262, 264, 273, 276, 280, 281, 283, 290, 296, 298, 304, 308, 309, 316, 320, 324, 326, 327, 330, 333, 335, 340, 342, 345, 347, 349, 350, 357, 358, 363, 366, 370, 374, 383, 384, 385, 389, 390, 391, 409, 414, 418, 429, 430, 435, 436, 439, 445, 449, 465, 466, 468, 485, 487, 492, 493, 494, 517, 524, 525, 533, 534, 545, 557, 575, 584, 585, 590, 595, 600, 609, 617, 627, 630, 631, 632, 634, 642, 660, 666, 667, 670, 686, 687, 688, 691, 694, 696, 698, 714, 724, 725, 726, 728, 734, 735, 742, 746, 749, 761, 774, 780, 782, 786, 791, 800, 805, 806, 807, 808, 809, 812, 813, 816, 821]\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[33, 34, 57, 106, 200, 281, 335, 366, 430, 595, 617, 642, 724, 725, 735, 761, 780]\n",
      "Run 3\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[9, 14, 21, 23, 30, 31, 33, 34, 38, 44, 48, 59, 70, 78, 81, 89, 90, 98, 101, 105, 115, 128, 135, 142, 153, 155, 157, 161, 164, 165, 176, 178, 179, 198, 200, 204, 210, 214, 215, 225, 237, 238, 239, 240, 241, 242, 243, 246, 252, 264, 281, 285, 288, 290, 294, 297, 301, 303, 304, 306, 319, 323, 328, 335, 338, 344, 347, 350, 351, 358, 359, 360, 367, 375, 384, 385, 387, 389, 390, 392, 398, 401, 404, 406, 415, 416, 425, 428, 429, 430, 440, 443, 447, 454, 455, 457, 461, 471, 472, 476, 481, 482, 483, 484, 491, 503, 510, 549, 552, 555, 560, 562, 572, 574, 576, 581, 586, 588, 592, 593, 605, 608, 612, 614, 615, 620, 633, 634, 641, 644, 645, 650, 651, 653, 654, 667, 668, 671, 672, 673, 674, 676, 682, 690, 692, 695, 700, 701, 715, 725, 728, 730, 741, 743, 748, 752, 753, 754, 756, 765, 766, 770, 771, 772, 773, 782, 783, 784, 786, 787, 788, 792, 795, 797, 798, 803, 815, 816, 823]\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[9, 33, 34, 128, 153, 164, 200, 239, 242, 243, 290, 306, 319, 328, 344, 350, 384, 430, 510, 614, 620, 641, 671, 725, 772, 786, 795]\n",
      "Run 4\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[3, 5, 8, 20, 21, 30, 31, 33, 34, 35, 36, 56, 57, 58, 59, 65, 77, 78, 79, 81, 82, 84, 85, 89, 90, 92, 96, 110, 125, 131, 137, 144, 151, 155, 156, 164, 166, 167, 175, 177, 185, 186, 197, 198, 200, 204, 205, 218, 223, 226, 233, 234, 235, 242, 245, 256, 259, 263, 266, 276, 277, 280, 281, 283, 285, 296, 300, 302, 303, 304, 306, 316, 319, 321, 327, 331, 334, 336, 337, 338, 351, 355, 366, 367, 369, 374, 375, 377, 381, 383, 385, 388, 411, 412, 418, 429, 430, 434, 437, 446, 447, 453, 457, 461, 463, 465, 466, 467, 469, 470, 471, 472, 480, 481, 482, 486, 491, 493, 497, 511, 514, 517, 518, 521, 530, 537, 538, 539, 543, 556, 563, 568, 583, 588, 590, 595, 596, 605, 610, 620, 627, 628, 631, 635, 647, 657, 672, 675, 685, 692, 694, 695, 707, 733, 736, 745, 757, 762, 767, 772, 773, 774, 776, 777, 780, 785, 788, 794, 801, 818, 820, 823, 825]\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[33, 34, 58, 144, 166, 175, 177, 233, 383, 388, 430, 466, 467, 537, 620, 692, 733, 780, 825]\n",
      "Run 5\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[1, 7, 9, 10, 14, 15, 20, 26, 30, 31, 32, 33, 34, 39, 53, 56, 57, 58, 64, 69, 71, 72, 78, 79, 85, 87, 92, 98, 100, 112, 117, 127, 128, 144, 145, 147, 161, 164, 166, 167, 168, 174, 176, 178, 182, 183, 194, 199, 208, 219, 223, 224, 235, 240, 244, 270, 271, 272, 276, 280, 281, 283, 289, 299, 306, 308, 309, 310, 311, 319, 325, 326, 336, 339, 341, 357, 358, 360, 366, 368, 374, 375, 379, 384, 385, 388, 398, 407, 416, 431, 441, 442, 448, 455, 456, 476, 478, 481, 510, 517, 524, 537, 547, 555, 557, 574, 585, 590, 593, 595, 596, 597, 598, 599, 611, 620, 635, 640, 644, 651, 653, 657, 658, 664, 668, 670, 673, 675, 685, 696, 725, 728, 738, 740, 741, 744, 747, 752, 759, 761, 765, 766, 777, 779, 780, 794, 798, 801, 802, 803, 813]\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[14, 15, 33, 34, 58, 161, 166, 306, 326, 336, 384, 510, 537, 640, 644, 685, 725, 780]\n"
     ]
    }
   ],
   "source": [
    "MiniRocketWindows = GenerateWindowsTest(5, \"MiniRocket\", 50, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[5, 15, 22, 23, 31, 44, 45, 47, 48, 55, 56, 58, 61, 63, 67, 68, 72, 86, 87, 95, 108, 116, 117, 126, 128, 147, 151, 154, 155, 168, 171, 174, 184, 198, 208, 212, 215, 221, 232, 233, 240, 246, 254, 255, 256, 262, 270, 272, 283, 287, 291, 305, 306, 317, 326, 329, 359, 367, 375, 383, 388, 412, 413, 427, 430, 434, 437, 443, 466, 489, 492, 493, 497, 499, 509, 510, 511, 516, 517, 521, 536, 537, 538, 556, 557, 562, 563, 576, 577, 594, 595, 596, 597, 603, 606, 627, 631, 632, 634, 654, 657, 658, 665, 668, 673, 675, 677, 678, 683, 687, 700, 701, 702, 706, 710, 718, 724, 725, 731, 732, 735, 736, 772, 780, 792, 798, 811, 813, 817, 818, 825]\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[198, 240, 256, 326, 359, 437, 493, 654, 657, 702, 724, 780]\n",
      "Run 2\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[3, 6, 9, 16, 23, 24, 33, 34, 46, 50, 53, 54, 57, 58, 59, 63, 71, 72, 74, 80, 82, 86, 97, 105, 106, 108, 118, 126, 127, 132, 139, 142, 145, 146, 150, 154, 160, 161, 172, 192, 193, 194, 195, 196, 201, 209, 224, 225, 232, 235, 239, 240, 246, 247, 249, 250, 264, 272, 275, 276, 281, 290, 296, 301, 306, 310, 317, 318, 319, 322, 323, 324, 325, 326, 327, 335, 340, 341, 349, 350, 352, 355, 358, 384, 389, 390, 391, 399, 408, 409, 416, 421, 426, 437, 452, 454, 455, 460, 473, 474, 476, 479, 485, 492, 500, 521, 537, 539, 547, 549, 551, 559, 569, 571, 574, 584, 586, 590, 596, 597, 603, 610, 619, 620, 622, 634, 635, 636, 638, 639, 641, 643, 648, 650, 654, 657, 658, 661, 671, 673, 684, 689, 690, 695, 697, 715, 717, 721, 732, 736, 738, 739, 741, 743, 745, 756, 758, 782, 783, 786, 787, 793, 797, 803, 805, 812, 813, 815, 817, 818]\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[9, 34, 54, 58, 86, 118, 161, 172, 224, 232, 247, 355, 358, 521, 596, 620, 634, 639, 650, 658, 689, 715, 717, 732, 786, 793]\n",
      "Run 3\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[7, 9, 15, 33, 34, 43, 49, 56, 57, 58, 70, 71, 72, 77, 86, 87, 91, 104, 106, 127, 139, 141, 143, 145, 161, 162, 165, 171, 178, 179, 187, 193, 198, 200, 201, 206, 208, 218, 221, 230, 234, 243, 250, 256, 283, 287, 288, 289, 293, 296, 298, 300, 303, 304, 306, 317, 321, 322, 323, 324, 326, 327, 328, 330, 342, 350, 357, 358, 367, 373, 374, 376, 382, 383, 393, 404, 416, 418, 427, 429, 432, 436, 445, 447, 458, 472, 492, 493, 510, 514, 515, 523, 529, 537, 543, 553, 558, 565, 593, 604, 622, 630, 631, 633, 636, 637, 639, 640, 641, 642, 644, 645, 652, 654, 658, 671, 675, 680, 688, 689, 692, 696, 698, 700, 703, 709, 710, 715, 727, 736, 743, 749, 780, 789, 804, 805, 811, 817, 818, 822]\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[9, 34, 49, 58, 86, 104, 201, 218, 243, 256, 283, 303, 306, 358, 376, 393, 429, 432, 493, 510, 523, 537, 543, 593, 654, 680]\n",
      "Run 4\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[1, 7, 10, 14, 17, 31, 34, 59, 62, 63, 68, 70, 85, 88, 90, 92, 93, 103, 118, 146, 148, 164, 165, 166, 175, 178, 198, 205, 209, 212, 221, 235, 239, 250, 251, 256, 260, 269, 276, 281, 282, 286, 293, 303, 323, 328, 356, 357, 362, 370, 375, 383, 384, 389, 398, 401, 402, 403, 412, 417, 418, 431, 443, 466, 493, 495, 511, 522, 537, 539, 540, 542, 553, 555, 584, 585, 588, 595, 597, 600, 601, 630, 642, 654, 661, 664, 665, 669, 680, 683, 696, 698, 702, 719, 722, 724, 750, 756, 759, 777, 778, 780, 782, 791, 792, 794, 805]\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[34, 90, 165, 175, 198, 256, 260, 328, 511, 683, 724, 794, 805]\n",
      "Run 5\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[6, 9, 17, 19, 20, 24, 25, 30, 31, 33, 38, 40, 48, 55, 56, 58, 59, 61, 63, 68, 75, 77, 82, 84, 86, 92, 99, 102, 103, 118, 128, 129, 135, 136, 143, 144, 145, 147, 148, 164, 166, 167, 172, 174, 175, 177, 187, 188, 189, 191, 193, 205, 206, 208, 215, 216, 220, 221, 224, 231, 232, 233, 237, 242, 247, 248, 250, 251, 254, 255, 256, 262, 264, 271, 272, 273, 287, 291, 301, 304, 311, 317, 318, 319, 322, 326, 327, 330, 333, 335, 341, 342, 343, 345, 358, 375, 376, 377, 378, 379, 385, 387, 394, 398, 399, 403, 405, 407, 416, 420, 421, 424, 425, 426, 428, 430, 432, 436, 439, 441, 449, 453, 456, 464, 465, 468, 469, 470, 475, 480, 482, 485, 486, 490, 492, 506, 513, 516, 518, 521, 529, 533, 535, 543, 546, 547, 550, 555, 557, 565, 571, 578, 585, 588, 595, 596, 597, 602, 603, 612, 613, 616, 617, 620, 621, 625, 626, 627, 630, 632, 634, 637, 641, 642, 649, 650, 651, 657, 659, 663, 666, 670, 671, 680, 686, 691, 698, 702, 704, 705, 706, 707, 709, 724, 725, 732, 736, 737, 738, 739, 740, 741, 744, 752, 757, 766, 770, 774, 779, 780, 787, 794, 797, 798, 803, 810]\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[9, 33, 118, 187, 430, 436, 449, 469, 521, 597, 603, 620, 630, 642, 651, 794]\n",
      "Run 1\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[13, 15, 21, 22, 26, 33, 34, 58, 63, 83, 85, 105, 127, 128, 134, 139, 141, 147, 148, 156, 159, 175, 183, 184, 190, 196, 198, 200, 201, 208, 216, 224, 226, 234, 240, 243, 254, 255, 256, 271, 280, 293, 328, 329, 342, 349, 350, 358, 369, 375, 394, 403, 436, 437, 438, 439, 444, 469, 493, 494, 500, 525, 530, 533, 535, 536, 539, 542, 543, 545, 556, 557, 574, 576, 577, 600, 602, 640, 641, 642, 649, 650, 653, 654, 657, 678, 679, 680, 681, 690, 700, 717, 728, 729, 733, 734, 739, 742, 759, 761, 773, 776, 780, 782, 806, 816, 823, 825]\n",
      "Window positions from validation with accuracy above threshold for run 1\n",
      "[33, 34, 198, 271, 293, 342, 358, 650, 654, 657, 733]\n",
      "Run 2\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[1, 5, 7, 8, 34, 51, 60, 66, 75, 79, 81, 84, 86, 87, 92, 95, 98, 104, 109, 119, 128, 144, 145, 147, 152, 162, 163, 164, 174, 176, 181, 185, 187, 208, 218, 219, 223, 227, 231, 232, 237, 247, 256, 264, 267, 276, 283, 284, 285, 306, 328, 338, 339, 340, 352, 358, 363, 369, 382, 383, 397, 418, 432, 433, 442, 445, 450, 466, 476, 479, 485, 491, 492, 493, 494, 495, 496, 497, 510, 511, 512, 513, 514, 530, 538, 539, 540, 546, 555, 582, 584, 586, 589, 590, 616, 617, 620, 632, 633, 635, 636, 641, 642, 657, 660, 667, 668, 683, 690, 692, 696, 699, 700, 701, 704, 714, 719, 724, 728, 738, 780, 784, 788, 792, 793, 805, 807]\n",
      "Window positions from validation with accuracy above threshold for run 2\n",
      "[128, 185, 223, 256, 283, 476, 546, 584, 620, 641, 642, 780]\n",
      "Run 3\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[3, 6, 7, 24, 25, 33, 38, 53, 55, 56, 59, 77, 91, 92, 95, 104, 120, 126, 128, 142, 143, 152, 153, 154, 164, 165, 169, 175, 177, 178, 184, 193, 198, 200, 201, 207, 208, 217, 218, 256, 264, 272, 281, 287, 316, 317, 319, 323, 326, 327, 329, 333, 335, 340, 348, 349, 357, 358, 382, 394, 398, 418, 441, 443, 454, 476, 478, 479, 485, 488, 494, 499, 500, 501, 502, 511, 523, 545, 547, 556, 557, 596, 605, 607, 614, 620, 623, 630, 632, 640, 646, 650, 654, 662, 683, 693, 694, 698, 712, 724, 725, 726, 727, 733, 734, 735, 736, 740, 741, 742, 751, 752, 754, 756, 762, 776, 779, 780, 782, 786, 790, 794, 797, 801, 805, 824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window positions from validation with accuracy above threshold for run 3\n",
      "[33, 120, 128, 153, 154, 164, 193, 218, 264, 272, 281, 357, 358, 382, 476, 485, 556, 632, 654, 733, 756, 780]\n",
      "Run 4\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[0, 9, 16, 31, 38, 39, 49, 52, 55, 56, 57, 58, 59, 68, 81, 89, 90, 91, 93, 97, 118, 120, 125, 131, 139, 147, 157, 158, 160, 161, 164, 168, 174, 175, 179, 182, 183, 184, 193, 198, 199, 207, 216, 218, 219, 222, 242, 246, 247, 283, 287, 289, 300, 301, 302, 307, 313, 318, 319, 322, 328, 333, 335, 357, 358, 359, 360, 369, 397, 407, 417, 424, 440, 442, 457, 462, 464, 466, 470, 475, 500, 510, 511, 512, 538, 539, 540, 557, 558, 560, 566, 575, 577, 578, 586, 587, 588, 589, 593, 600, 609, 612, 613, 617, 620, 625, 630, 631, 636, 641, 642, 648, 650, 654, 655, 657, 660, 668, 686, 687, 688, 692, 694, 695, 700, 701, 702, 704, 707, 708, 710, 717, 724, 732, 734, 743, 747, 776, 777, 781, 789, 795, 805, 806, 811, 816, 817, 818, 821]\n",
      "Window positions from validation with accuracy above threshold for run 4\n",
      "[9, 58, 59, 93, 198, 246, 300, 328, 440, 500, 630, 631, 686, 724, 734]\n",
      "Run 5\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 69%\n",
      "Progress: 79%\n",
      "Progress: 89%\n",
      "Progress: 99%\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[9, 23, 29, 33, 35, 42, 43, 51, 57, 58, 60, 61, 73, 78, 80, 86, 104, 106, 112, 118, 128, 130, 131, 135, 139, 140, 142, 143, 145, 147, 149, 154, 157, 158, 159, 160, 161, 162, 163, 166, 171, 179, 185, 193, 211, 218, 219, 220, 223, 246, 247, 250, 251, 252, 253, 255, 258, 266, 271, 275, 279, 285, 293, 294, 298, 299, 303, 305, 306, 307, 312, 314, 317, 318, 319, 321, 327, 328, 329, 339, 340, 349, 357, 359, 383, 384, 392, 412, 416, 418, 431, 433, 437, 438, 440, 441, 446, 447, 453, 457, 461, 465, 466, 483, 484, 491, 506, 514, 542, 552, 553, 563, 564, 565, 568, 575, 576, 577, 587, 592, 595, 602, 613, 616, 617, 619, 623, 627, 630, 631, 632, 634, 642, 654, 657, 673, 675, 680, 698, 701, 703, 706, 715, 717, 723, 724, 725, 727, 733, 738, 741, 744, 758, 761, 769, 773, 776, 781, 786, 793, 794, 813, 817]\n",
      "Window positions from validation with accuracy above threshold for run 5\n",
      "[23, 33, 57, 58, 128, 140, 223, 271, 293, 298, 299, 306, 314, 328, 642, 654, 657, 717, 727, 733, 786]\n"
     ]
    }
   ],
   "source": [
    "MrSEQLWindows = GenerateWindowsTest(5, \"MrSEQL\", 50, 0.6)\n",
    "RandomForestWindows = GenerateWindowsTest(5, \"RandomForest\", 50, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1700-1750', 5),\n",
       " ('36250-36300', 4),\n",
       " ('39000-39050', 4),\n",
       " ('1650-1700', 4),\n",
       " ('26850-26900', 3),\n",
       " ('21500-21550', 3),\n",
       " ('16300-16350', 2),\n",
       " ('36650-36700', 2),\n",
       " ('10000-10050', 2),\n",
       " ('15300-15350', 2),\n",
       " ('19200-19250', 2),\n",
       " ('25500-25550', 2),\n",
       " ('31000-31050', 2),\n",
       " ('2900-2950', 2),\n",
       " ('8300-8350', 2),\n",
       " ('4650-4700', 1),\n",
       " ('7000-7050', 1),\n",
       " ('9900-9950', 1),\n",
       " ('19250-19300', 1),\n",
       " ('30550-30600', 1),\n",
       " ('2850-2900', 1),\n",
       " ('5300-5350', 1),\n",
       " ('14050-14100', 1),\n",
       " ('16750-16800', 1),\n",
       " ('18300-18350', 1),\n",
       " ('29750-29800', 1),\n",
       " ('30850-30900', 1),\n",
       " ('32100-32150', 1),\n",
       " ('36200-36250', 1),\n",
       " ('36750-36800', 1),\n",
       " ('38050-38100', 1),\n",
       " ('450-500', 1),\n",
       " ('6400-6450', 1),\n",
       " ('7650-7700', 1),\n",
       " ('8200-8250', 1),\n",
       " ('11950-12000', 1),\n",
       " ('12100-12150', 1),\n",
       " ('12150-12200', 1),\n",
       " ('14500-14550', 1),\n",
       " ('15950-16000', 1),\n",
       " ('16400-16450', 1),\n",
       " ('17200-17250', 1),\n",
       " ('17500-17550', 1),\n",
       " ('30700-30750', 1),\n",
       " ('32050-32100', 1),\n",
       " ('33550-33600', 1),\n",
       " ('38600-38650', 1),\n",
       " ('39300-39350', 1),\n",
       " ('39750-39800', 1),\n",
       " ('7200-7250', 1),\n",
       " ('8750-8800', 1),\n",
       " ('8850-8900', 1),\n",
       " ('11650-11700', 1),\n",
       " ('19150-19200', 1),\n",
       " ('19400-19450', 1),\n",
       " ('23300-23350', 1),\n",
       " ('23350-23400', 1),\n",
       " ('34600-34650', 1),\n",
       " ('41250-41300', 1),\n",
       " ('700-750', 1),\n",
       " ('750-800', 1),\n",
       " ('8050-8100', 1),\n",
       " ('16800-16850', 1),\n",
       " ('32000-32050', 1),\n",
       " ('32200-32250', 1),\n",
       " ('34250-34300', 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MiniRocketWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs2054402</th>\n",
       "      <th>rs6783510</th>\n",
       "      <th>rs2219740</th>\n",
       "      <th>rs28549095</th>\n",
       "      <th>rs6548843</th>\n",
       "      <th>rs1973163</th>\n",
       "      <th>rs7434172</th>\n",
       "      <th>rs12714541</th>\n",
       "      <th>rs1382069</th>\n",
       "      <th>rs6548846</th>\n",
       "      <th>...</th>\n",
       "      <th>rs9877278</th>\n",
       "      <th>rs10460916</th>\n",
       "      <th>rs11127807</th>\n",
       "      <th>rs6806032</th>\n",
       "      <th>rs12486048</th>\n",
       "      <th>rs9860784</th>\n",
       "      <th>rs538361</th>\n",
       "      <th>rs12714558</th>\n",
       "      <th>rs7611473</th>\n",
       "      <th>rs1473624</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rs2054402  rs6783510  rs2219740  rs28549095  rs6548843  rs1973163  \\\n",
       "0            2          2          2           2          2          1   \n",
       "1            2          2          2           2          2          2   \n",
       "2            2          2          2           2          2          1   \n",
       "3            1          1          1           1          1          2   \n",
       "4            1          1          1           1          1          2   \n",
       "..         ...        ...        ...         ...        ...        ...   \n",
       "104          1          1          1           1          1          2   \n",
       "105          1          1          1           1          1          2   \n",
       "106          1          1          1           1          1          2   \n",
       "107          1          1          1           1          1          2   \n",
       "108          2          2          2           2          2          1   \n",
       "\n",
       "     rs7434172  rs12714541  rs1382069  rs6548846  ...  rs9877278  rs10460916  \\\n",
       "0            1           1          1          1  ...          1           2   \n",
       "1            2           2          2          2  ...          2           1   \n",
       "2            1           2          2          2  ...          2           1   \n",
       "3            2           2          2          2  ...          1           1   \n",
       "4            2           2          2          2  ...          1           2   \n",
       "..         ...         ...        ...        ...  ...        ...         ...   \n",
       "104          2           1          1          1  ...          2           1   \n",
       "105          2           1          1          1  ...          1           1   \n",
       "106          2           1          1          1  ...          0           2   \n",
       "107          2           1          1          1  ...          1           1   \n",
       "108          1           2          2          2  ...          1           2   \n",
       "\n",
       "     rs11127807  rs6806032  rs12486048  rs9860784  rs538361  rs12714558  \\\n",
       "0             1          2           1          1         1           1   \n",
       "1             1          1           1          2         2           2   \n",
       "2             2          1           0          2         1           2   \n",
       "3             1          1           1          2         2           2   \n",
       "4             0          2           2          2         2           2   \n",
       "..          ...        ...         ...        ...       ...         ...   \n",
       "104           1          1           1          2         2           2   \n",
       "105           1          1           1          2         2           2   \n",
       "106           0          2           2          2         2           2   \n",
       "107           1          1           1          2         2           2   \n",
       "108           1          2           1          1         1           1   \n",
       "\n",
       "     rs7611473  rs1473624  \n",
       "0            1          2  \n",
       "1            1          1  \n",
       "2            2          2  \n",
       "3            1          2  \n",
       "4            0          1  \n",
       "..         ...        ...  \n",
       "104          1          1  \n",
       "105          1          2  \n",
       "106          0          2  \n",
       "107          1          2  \n",
       "108          1          2  \n",
       "\n",
       "[109 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.iloc[:, 1700:1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for RandomForest on selected SNP window: 0.7303030303030303\n"
     ]
    }
   ],
   "source": [
    "# Classifying GWAS data using RandomForest\n",
    "\n",
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTtest, yTrain, yTest = train_test_split(dfTest.iloc[:, 1650:1750], phenotype, train_size=0.7)\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(xTrain, yTrain)\n",
    "    \n",
    "    yPredicted = rfc.predict(xTtest)\n",
    "    results.append(accuracy_score(yTest, yPredicted))\n",
    "    \n",
    "print(f\"Average accuracy for RandomForest on selected SNP window: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for MiniRocket on selected SNP window: 0.7151515151515153\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n in range(0,10):\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(dfTest.iloc[:, 1650:1750], phenotype, train_size=0.7)\n",
    "\n",
    "    \n",
    "    xTrain = from_2d_array_to_nested(xTrain)\n",
    "    xTest = from_2d_array_to_nested(xTest)\n",
    "    \n",
    "    minirocket = MiniRocket()\n",
    "    minirocket.fit(xTrain)\n",
    "    xTrainTransform = minirocket.transform(xTrain)\n",
    "\n",
    "    classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    classifier.fit(xTrainTransform, yTrain)\n",
    "\n",
    "    xTestTransform = minirocket.transform(xTest)\n",
    "    yPredict = classifier.predict(xTestTransform)\n",
    "\n",
    "    results.append(accuracy_score(yTest, yPredict))\n",
    "    \n",
    "print(f\"Average accuracy for MiniRocket on selected SNP window: {sum(results) / len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
